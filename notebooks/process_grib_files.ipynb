{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "371cf10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "from src.manage_grib_files import process_london_precipitation_data, process_my_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e565bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_file = \"./grib/london_era5land_hourly_t2m_2025\"\n",
    "# grib_file = out_file + '.grib'\n",
    "\n",
    "# ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "# if ds is not None:\n",
    "#     print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "#     print(\"\\nTo work with your data:\")\n",
    "#     print(\"1. Use ds[variable_name] to access variables\")\n",
    "#     print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "#     print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "# df = process_my_data(ds, \"2025_london_era5_temperature\")\n",
    "\n",
    "# for filename in glob.glob(\"./grib/data*\"):\n",
    "#     os.remove(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134a1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year = 1998\n",
    "# area = 'london'\n",
    "\n",
    "# out_file = './grib/' + area + '_era5land_hourly_tp_' + str(year)\n",
    "# grib_file = out_file + '.grib'\n",
    "\n",
    "# print(grib_file)\n",
    "# file_process = str(year) + '_' + area + '_era5_precipitation'\n",
    "# print(file_process)\n",
    "\n",
    "# ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "# if ds is not None:\n",
    "#     print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "#     print(\"\\nTo work with your data:\")\n",
    "#     print(\"1. Use ds[variable_name] to access variables\")\n",
    "#     print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "#     print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "# df = process_my_data(ds, file_process)\n",
    "\n",
    "# for filename in glob.glob(\"./grib/data*\"):\n",
    "#     os.remove(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1242acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: ./grib/puglia_era5land_hourly_tp_2010.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: grib\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: grib\\data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 366, 'step': 24, 'latitude': 18, 'longitude': 33}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2009-12-31T00:00:00.000000000 to 2010-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 40.2 to 41.9 (18 points)\n",
      "   longitude: 15.3 to 18.5 (33 points)\n",
      "   valid_time: 2009-12-31T01:00:00.000000000 to 2011-01-01T00:00:00.000000000 (8784 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 366, 'step': 24, 'latitude': 18, 'longitude': 33}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2009-12-31T00:00:00.000000000 to 2010-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 41.9 to 40.2 (18 points)\n",
      "   longitude: 15.3 to 18.5 (33 points)\n",
      "   valid_time: ['2009-12-31T01:00:00.000000000' '2009-12-31T02:00:00.000000000'\n",
      " '2009-12-31T03:00:00.000000000' '2009-12-31T04:00:00.000000000'\n",
      " '2009-12-31T05:00:00.000000000' '2009-12-31T06:00:00.000000000'\n",
      " '2009-12-31T07:00:00.000000000' '2009-12-31T08:00:00.000000000'\n",
      " '2009-12-31T09:00:00.000000000' '2009-12-31T10:00:00.000000000'\n",
      " '2009-12-31T11:00:00.000000000' '2009-12-31T12:00:00.000000000'\n",
      " '2009-12-31T13:00:00.000000000' '2009-12-31T14:00:00.000000000'\n",
      " '2009-12-31T15:00:00.000000000' '2009-12-31T16:00:00.000000000'\n",
      " '2009-12-31T17:00:00.000000000' '2009-12-31T18:00:00.000000000'\n",
      " '2009-12-31T19:00:00.000000000' '2009-12-31T20:00:00.000000000'\n",
      " '2009-12-31T21:00:00.000000000' '2009-12-31T22:00:00.000000000'\n",
      " '2009-12-31T23:00:00.000000000' '2010-01-01T00:00:00.000000000'] to ['2010-12-31T01:00:00.000000000' '2010-12-31T02:00:00.000000000'\n",
      " '2010-12-31T03:00:00.000000000' '2010-12-31T04:00:00.000000000'\n",
      " '2010-12-31T05:00:00.000000000' '2010-12-31T06:00:00.000000000'\n",
      " '2010-12-31T07:00:00.000000000' '2010-12-31T08:00:00.000000000'\n",
      " '2010-12-31T09:00:00.000000000' '2010-12-31T10:00:00.000000000'\n",
      " '2010-12-31T11:00:00.000000000' '2010-12-31T12:00:00.000000000'\n",
      " '2010-12-31T13:00:00.000000000' '2010-12-31T14:00:00.000000000'\n",
      " '2010-12-31T15:00:00.000000000' '2010-12-31T16:00:00.000000000'\n",
      " '2010-12-31T17:00:00.000000000' '2010-12-31T18:00:00.000000000'\n",
      " '2010-12-31T19:00:00.000000000' '2010-12-31T20:00:00.000000000'\n",
      " '2010-12-31T21:00:00.000000000' '2010-12-31T22:00:00.000000000'\n",
      " '2010-12-31T23:00:00.000000000' '2011-01-01T00:00:00.000000000'] (8784 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (366, 24, 18, 33)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.09787493944168091\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 2680560 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2010_puglia_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 244.47 MB\n",
      "📊 Long format sample:\n",
      "            time   step  latitude  longitude  number  surface valid_time  \\\n",
      "13663 2009-12-31 1 days      41.9       15.4       0      0.0 2010-01-01   \n",
      "13664 2009-12-31 1 days      41.9       15.5       0      0.0 2010-01-01   \n",
      "13667 2009-12-31 1 days      41.9       15.8       0      0.0 2010-01-01   \n",
      "13668 2009-12-31 1 days      41.9       15.9       0      0.0 2010-01-01   \n",
      "13669 2009-12-31 1 days      41.9       16.0       0      0.0 2010-01-01   \n",
      "\n",
      "                 tp  \n",
      "13663  7.736683e-06  \n",
      "13664  4.351138e-07  \n",
      "13667  4.351138e-07  \n",
      "13668  6.437301e-07  \n",
      "13669  1.388788e-06  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8760 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2010_puglia_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.47 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time        tp\n",
      "time                                                                     \n",
      "2009-12-31 1 days 00:00:00       0      0.0 2010-01-01 00:00:00  0.000027\n",
      "2010-01-01 0 days 01:00:00       0      0.0 2010-01-01 01:00:00  0.000138\n",
      "2010-01-01 0 days 02:00:00       0      0.0 2010-01-01 02:00:00  0.000284\n",
      "2010-01-01 0 days 03:00:00       0      0.0 2010-01-01 03:00:00  0.000386\n",
      "2010-01-01 0 days 04:00:00       0      0.0 2010-01-01 04:00:00  0.000469\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 7344 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2010_puglia_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.47 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude  longitude  number  surface        tp\n",
      "1 0 days 01:00:00      41.9       15.4       0      0.0  0.000082\n",
      "2 0 days 01:00:00      41.9       15.5       0      0.0  0.000078\n",
      "5 0 days 01:00:00      41.9       15.8       0      0.0  0.000082\n",
      "6 0 days 01:00:00      41.9       15.9       0      0.0  0.000086\n",
      "7 0 days 01:00:00      41.9       16.0       0      0.0  0.000088\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2010_puglia_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2010_puglia_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2010_puglia_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 2680560 rows\n"
     ]
    }
   ],
   "source": [
    "years = np.arange(2010, 2011)\n",
    "area = 'puglia'\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    out_file = './grib/' + area + '_era5land_hourly_tp_' + str(year)\n",
    "    grib_file = out_file + '.grib'\n",
    "\n",
    "    file_process = str(year) + '_' + area + '_era5_precipitation'\n",
    "\n",
    "    ds = process_london_precipitation_data(grib_file)\n",
    "        \n",
    "    if ds is not None:\n",
    "        print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "        print(\"\\nTo work with your data:\")\n",
    "        print(\"1. Use ds[variable_name] to access variables\")\n",
    "        print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "        print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "    df = process_my_data(ds, file_process)\n",
    "\n",
    "    for filename in glob.glob(\"./grib/data*\"):\n",
    "        os.remove(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec92a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32731cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4104905c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "257a9609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: ./grib/london_era5land_hourly_tp_2000.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: grib\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: grib\\data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 367, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 1999-12-31T00:00:00.000000000 to 2000-12-31T00:00:00.000000000 (367 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 51.4 to 51.6 (3 points)\n",
      "   longitude: -0.2 to 0.1 (4 points)\n",
      "   valid_time: 1999-12-31T01:00:00.000000000 to 2001-01-01T00:00:00.000000000 (8808 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 367, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 1999-12-31T00:00:00.000000000 to 2000-12-31T00:00:00.000000000 (367 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: [51.6 51.5 51.4]\n",
      "   longitude: [-2.00000000e-01 -1.00000000e-01  2.77555756e-17  1.00000000e-01]\n",
      "   valid_time: ['1999-12-31T01:00:00.000000000' '1999-12-31T02:00:00.000000000'\n",
      " '1999-12-31T03:00:00.000000000' '1999-12-31T04:00:00.000000000'\n",
      " '1999-12-31T05:00:00.000000000' '1999-12-31T06:00:00.000000000'\n",
      " '1999-12-31T07:00:00.000000000' '1999-12-31T08:00:00.000000000'\n",
      " '1999-12-31T09:00:00.000000000' '1999-12-31T10:00:00.000000000'\n",
      " '1999-12-31T11:00:00.000000000' '1999-12-31T12:00:00.000000000'\n",
      " '1999-12-31T13:00:00.000000000' '1999-12-31T14:00:00.000000000'\n",
      " '1999-12-31T15:00:00.000000000' '1999-12-31T16:00:00.000000000'\n",
      " '1999-12-31T17:00:00.000000000' '1999-12-31T18:00:00.000000000'\n",
      " '1999-12-31T19:00:00.000000000' '1999-12-31T20:00:00.000000000'\n",
      " '1999-12-31T21:00:00.000000000' '1999-12-31T22:00:00.000000000'\n",
      " '1999-12-31T23:00:00.000000000' '2000-01-01T00:00:00.000000000'] to ['2000-12-31T01:00:00.000000000' '2000-12-31T02:00:00.000000000'\n",
      " '2000-12-31T03:00:00.000000000' '2000-12-31T04:00:00.000000000'\n",
      " '2000-12-31T05:00:00.000000000' '2000-12-31T06:00:00.000000000'\n",
      " '2000-12-31T07:00:00.000000000' '2000-12-31T08:00:00.000000000'\n",
      " '2000-12-31T09:00:00.000000000' '2000-12-31T10:00:00.000000000'\n",
      " '2000-12-31T11:00:00.000000000' '2000-12-31T12:00:00.000000000'\n",
      " '2000-12-31T13:00:00.000000000' '2000-12-31T14:00:00.000000000'\n",
      " '2000-12-31T15:00:00.000000000' '2000-12-31T16:00:00.000000000'\n",
      " '2000-12-31T17:00:00.000000000' '2000-12-31T18:00:00.000000000'\n",
      " '2000-12-31T19:00:00.000000000' '2000-12-31T20:00:00.000000000'\n",
      " '2000-12-31T21:00:00.000000000' '2000-12-31T22:00:00.000000000'\n",
      " '2000-12-31T23:00:00.000000000' '2001-01-01T00:00:00.000000000'] (8808 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (367, 24, 3, 4)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.03247427940368652\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 105408 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2000_london_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 8.47 MB\n",
      "📊 Long format sample:\n",
      "          time   step  latitude     longitude  number  surface valid_time  \\\n",
      "276 1999-12-31 1 days      51.6 -2.000000e-01       0      0.0 2000-01-01   \n",
      "277 1999-12-31 1 days      51.6 -1.000000e-01       0      0.0 2000-01-01   \n",
      "278 1999-12-31 1 days      51.6  2.775558e-17       0      0.0 2000-01-01   \n",
      "279 1999-12-31 1 days      51.6  1.000000e-01       0      0.0 2000-01-01   \n",
      "280 1999-12-31 1 days      51.5 -2.000000e-01       0      0.0 2000-01-01   \n",
      "\n",
      "           tp  \n",
      "276  0.000115  \n",
      "277  0.000110  \n",
      "278  0.000106  \n",
      "279  0.000115  \n",
      "280  0.000108  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8784 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2000_london_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time        tp\n",
      "time                                                                     \n",
      "1999-12-31 1 days 00:00:00       0      0.0 2000-01-01 00:00:00  0.000100\n",
      "2000-01-01 0 days 01:00:00       0      0.0 2000-01-01 01:00:00  0.000008\n",
      "2000-01-01 0 days 02:00:00       0      0.0 2000-01-01 02:00:00  0.000018\n",
      "2000-01-01 0 days 03:00:00       0      0.0 2000-01-01 03:00:00  0.000084\n",
      "2000-01-01 0 days 04:00:00       0      0.0 2000-01-01 04:00:00  0.000132\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 288 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2000_london_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.02 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude     longitude  number  surface        tp\n",
      "0 0 days 01:00:00      51.6 -2.000000e-01       0      0.0  0.000085\n",
      "1 0 days 01:00:00      51.6 -1.000000e-01       0      0.0  0.000083\n",
      "2 0 days 01:00:00      51.6  2.775558e-17       0      0.0  0.000082\n",
      "3 0 days 01:00:00      51.6  1.000000e-01       0      0.0  0.000081\n",
      "4 0 days 01:00:00      51.5 -2.000000e-01       0      0.0  0.000085\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2000_london_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2000_london_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2000_london_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 105408 rows\n",
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: ./grib/london_era5land_hourly_tp_2001.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: grib\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: grib\\data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2000-12-31T00:00:00.000000000 to 2001-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 51.4 to 51.6 (3 points)\n",
      "   longitude: -0.2 to 0.1 (4 points)\n",
      "   valid_time: 2000-12-31T01:00:00.000000000 to 2002-01-01T00:00:00.000000000 (8784 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2000-12-31T00:00:00.000000000 to 2001-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: [51.6 51.5 51.4]\n",
      "   longitude: [-2.00000000e-01 -1.00000000e-01  2.77555756e-17  1.00000000e-01]\n",
      "   valid_time: ['2000-12-31T01:00:00.000000000' '2000-12-31T02:00:00.000000000'\n",
      " '2000-12-31T03:00:00.000000000' '2000-12-31T04:00:00.000000000'\n",
      " '2000-12-31T05:00:00.000000000' '2000-12-31T06:00:00.000000000'\n",
      " '2000-12-31T07:00:00.000000000' '2000-12-31T08:00:00.000000000'\n",
      " '2000-12-31T09:00:00.000000000' '2000-12-31T10:00:00.000000000'\n",
      " '2000-12-31T11:00:00.000000000' '2000-12-31T12:00:00.000000000'\n",
      " '2000-12-31T13:00:00.000000000' '2000-12-31T14:00:00.000000000'\n",
      " '2000-12-31T15:00:00.000000000' '2000-12-31T16:00:00.000000000'\n",
      " '2000-12-31T17:00:00.000000000' '2000-12-31T18:00:00.000000000'\n",
      " '2000-12-31T19:00:00.000000000' '2000-12-31T20:00:00.000000000'\n",
      " '2000-12-31T21:00:00.000000000' '2000-12-31T22:00:00.000000000'\n",
      " '2000-12-31T23:00:00.000000000' '2001-01-01T00:00:00.000000000'] to ['2001-12-31T01:00:00.000000000' '2001-12-31T02:00:00.000000000'\n",
      " '2001-12-31T03:00:00.000000000' '2001-12-31T04:00:00.000000000'\n",
      " '2001-12-31T05:00:00.000000000' '2001-12-31T06:00:00.000000000'\n",
      " '2001-12-31T07:00:00.000000000' '2001-12-31T08:00:00.000000000'\n",
      " '2001-12-31T09:00:00.000000000' '2001-12-31T10:00:00.000000000'\n",
      " '2001-12-31T11:00:00.000000000' '2001-12-31T12:00:00.000000000'\n",
      " '2001-12-31T13:00:00.000000000' '2001-12-31T14:00:00.000000000'\n",
      " '2001-12-31T15:00:00.000000000' '2001-12-31T16:00:00.000000000'\n",
      " '2001-12-31T17:00:00.000000000' '2001-12-31T18:00:00.000000000'\n",
      " '2001-12-31T19:00:00.000000000' '2001-12-31T20:00:00.000000000'\n",
      " '2001-12-31T21:00:00.000000000' '2001-12-31T22:00:00.000000000'\n",
      " '2001-12-31T23:00:00.000000000' '2002-01-01T00:00:00.000000000'] (8784 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (366, 24, 3, 4)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.021790260449051857\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 105120 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2001_london_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 8.42 MB\n",
      "📊 Long format sample:\n",
      "          time   step  latitude     longitude  number  surface valid_time  \\\n",
      "276 2000-12-31 1 days      51.6 -2.000000e-01       0      0.0 2001-01-01   \n",
      "277 2000-12-31 1 days      51.6 -1.000000e-01       0      0.0 2001-01-01   \n",
      "278 2000-12-31 1 days      51.6  2.775558e-17       0      0.0 2001-01-01   \n",
      "279 2000-12-31 1 days      51.6  1.000000e-01       0      0.0 2001-01-01   \n",
      "280 2000-12-31 1 days      51.5 -2.000000e-01       0      0.0 2001-01-01   \n",
      "\n",
      "           tp  \n",
      "276  0.007046  \n",
      "277  0.006665  \n",
      "278  0.006283  \n",
      "279  0.006082  \n",
      "280  0.007356  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8760 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2001_london_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time        tp\n",
      "time                                                                     \n",
      "2000-12-31 1 days 00:00:00       0      0.0 2001-01-01 00:00:00  0.006848\n",
      "2001-01-01 0 days 01:00:00       0      0.0 2001-01-01 01:00:00  0.000666\n",
      "2001-01-01 0 days 02:00:00       0      0.0 2001-01-01 02:00:00  0.001246\n",
      "2001-01-01 0 days 03:00:00       0      0.0 2001-01-01 03:00:00  0.001422\n",
      "2001-01-01 0 days 04:00:00       0      0.0 2001-01-01 04:00:00  0.001455\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 288 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2001_london_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.02 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude     longitude  number  surface        tp\n",
      "0 0 days 01:00:00      51.6 -2.000000e-01       0      0.0  0.000068\n",
      "1 0 days 01:00:00      51.6 -1.000000e-01       0      0.0  0.000066\n",
      "2 0 days 01:00:00      51.6  2.775558e-17       0      0.0  0.000064\n",
      "3 0 days 01:00:00      51.6  1.000000e-01       0      0.0  0.000066\n",
      "4 0 days 01:00:00      51.5 -2.000000e-01       0      0.0  0.000072\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2001_london_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2001_london_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2001_london_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 105120 rows\n",
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: ./grib/london_era5land_hourly_tp_2002.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: grib\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: grib\\data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2001-12-31T00:00:00.000000000 to 2002-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 51.4 to 51.6 (3 points)\n",
      "   longitude: -0.2 to 0.1 (4 points)\n",
      "   valid_time: 2001-12-31T01:00:00.000000000 to 2003-01-01T00:00:00.000000000 (8784 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2001-12-31T00:00:00.000000000 to 2002-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: [51.6 51.5 51.4]\n",
      "   longitude: [-2.00000000e-01 -1.00000000e-01  2.77555756e-17  1.00000000e-01]\n",
      "   valid_time: ['2001-12-31T01:00:00.000000000' '2001-12-31T02:00:00.000000000'\n",
      " '2001-12-31T03:00:00.000000000' '2001-12-31T04:00:00.000000000'\n",
      " '2001-12-31T05:00:00.000000000' '2001-12-31T06:00:00.000000000'\n",
      " '2001-12-31T07:00:00.000000000' '2001-12-31T08:00:00.000000000'\n",
      " '2001-12-31T09:00:00.000000000' '2001-12-31T10:00:00.000000000'\n",
      " '2001-12-31T11:00:00.000000000' '2001-12-31T12:00:00.000000000'\n",
      " '2001-12-31T13:00:00.000000000' '2001-12-31T14:00:00.000000000'\n",
      " '2001-12-31T15:00:00.000000000' '2001-12-31T16:00:00.000000000'\n",
      " '2001-12-31T17:00:00.000000000' '2001-12-31T18:00:00.000000000'\n",
      " '2001-12-31T19:00:00.000000000' '2001-12-31T20:00:00.000000000'\n",
      " '2001-12-31T21:00:00.000000000' '2001-12-31T22:00:00.000000000'\n",
      " '2001-12-31T23:00:00.000000000' '2002-01-01T00:00:00.000000000'] to ['2002-12-31T01:00:00.000000000' '2002-12-31T02:00:00.000000000'\n",
      " '2002-12-31T03:00:00.000000000' '2002-12-31T04:00:00.000000000'\n",
      " '2002-12-31T05:00:00.000000000' '2002-12-31T06:00:00.000000000'\n",
      " '2002-12-31T07:00:00.000000000' '2002-12-31T08:00:00.000000000'\n",
      " '2002-12-31T09:00:00.000000000' '2002-12-31T10:00:00.000000000'\n",
      " '2002-12-31T11:00:00.000000000' '2002-12-31T12:00:00.000000000'\n",
      " '2002-12-31T13:00:00.000000000' '2002-12-31T14:00:00.000000000'\n",
      " '2002-12-31T15:00:00.000000000' '2002-12-31T16:00:00.000000000'\n",
      " '2002-12-31T17:00:00.000000000' '2002-12-31T18:00:00.000000000'\n",
      " '2002-12-31T19:00:00.000000000' '2002-12-31T20:00:00.000000000'\n",
      " '2002-12-31T21:00:00.000000000' '2002-12-31T22:00:00.000000000'\n",
      " '2002-12-31T23:00:00.000000000' '2003-01-01T00:00:00.000000000'] (8784 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (366, 24, 3, 4)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.024416223168373108\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 105120 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2002_london_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 8.43 MB\n",
      "📊 Long format sample:\n",
      "          time   step  latitude     longitude  number  surface valid_time  \\\n",
      "276 2001-12-31 1 days      51.6 -2.000000e-01       0      0.0 2002-01-01   \n",
      "277 2001-12-31 1 days      51.6 -1.000000e-01       0      0.0 2002-01-01   \n",
      "278 2001-12-31 1 days      51.6  2.775558e-17       0      0.0 2002-01-01   \n",
      "279 2001-12-31 1 days      51.6  1.000000e-01       0      0.0 2002-01-01   \n",
      "280 2001-12-31 1 days      51.5 -2.000000e-01       0      0.0 2002-01-01   \n",
      "\n",
      "           tp  \n",
      "276  0.000002  \n",
      "277  0.000002  \n",
      "278  0.000002  \n",
      "279  0.000002  \n",
      "280  0.000002  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8760 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2002_london_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time        tp\n",
      "time                                                                     \n",
      "2001-12-31 1 days 00:00:00       0      0.0 2002-01-01 00:00:00  0.000002\n",
      "2002-01-01 0 days 01:00:00       0      0.0 2002-01-01 01:00:00  0.000000\n",
      "2002-01-01 0 days 02:00:00       0      0.0 2002-01-01 02:00:00  0.000000\n",
      "2002-01-01 0 days 03:00:00       0      0.0 2002-01-01 03:00:00  0.000000\n",
      "2002-01-01 0 days 04:00:00       0      0.0 2002-01-01 04:00:00  0.000000\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 288 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2002_london_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.02 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude     longitude  number  surface        tp\n",
      "0 0 days 01:00:00      51.6 -2.000000e-01       0      0.0  0.000074\n",
      "1 0 days 01:00:00      51.6 -1.000000e-01       0      0.0  0.000074\n",
      "2 0 days 01:00:00      51.6  2.775558e-17       0      0.0  0.000073\n",
      "3 0 days 01:00:00      51.6  1.000000e-01       0      0.0  0.000074\n",
      "4 0 days 01:00:00      51.5 -2.000000e-01       0      0.0  0.000075\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2002_london_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2002_london_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2002_london_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 105120 rows\n",
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: ./grib/london_era5land_hourly_tp_2003.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: grib\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: grib\\data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2002-12-31T00:00:00.000000000 to 2003-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 51.4 to 51.6 (3 points)\n",
      "   longitude: -0.2 to 0.1 (4 points)\n",
      "   valid_time: 2002-12-31T01:00:00.000000000 to 2004-01-01T00:00:00.000000000 (8784 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2002-12-31T00:00:00.000000000 to 2003-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: [51.6 51.5 51.4]\n",
      "   longitude: [-2.00000000e-01 -1.00000000e-01  2.77555756e-17  1.00000000e-01]\n",
      "   valid_time: ['2002-12-31T01:00:00.000000000' '2002-12-31T02:00:00.000000000'\n",
      " '2002-12-31T03:00:00.000000000' '2002-12-31T04:00:00.000000000'\n",
      " '2002-12-31T05:00:00.000000000' '2002-12-31T06:00:00.000000000'\n",
      " '2002-12-31T07:00:00.000000000' '2002-12-31T08:00:00.000000000'\n",
      " '2002-12-31T09:00:00.000000000' '2002-12-31T10:00:00.000000000'\n",
      " '2002-12-31T11:00:00.000000000' '2002-12-31T12:00:00.000000000'\n",
      " '2002-12-31T13:00:00.000000000' '2002-12-31T14:00:00.000000000'\n",
      " '2002-12-31T15:00:00.000000000' '2002-12-31T16:00:00.000000000'\n",
      " '2002-12-31T17:00:00.000000000' '2002-12-31T18:00:00.000000000'\n",
      " '2002-12-31T19:00:00.000000000' '2002-12-31T20:00:00.000000000'\n",
      " '2002-12-31T21:00:00.000000000' '2002-12-31T22:00:00.000000000'\n",
      " '2002-12-31T23:00:00.000000000' '2003-01-01T00:00:00.000000000'] to ['2003-12-31T01:00:00.000000000' '2003-12-31T02:00:00.000000000'\n",
      " '2003-12-31T03:00:00.000000000' '2003-12-31T04:00:00.000000000'\n",
      " '2003-12-31T05:00:00.000000000' '2003-12-31T06:00:00.000000000'\n",
      " '2003-12-31T07:00:00.000000000' '2003-12-31T08:00:00.000000000'\n",
      " '2003-12-31T09:00:00.000000000' '2003-12-31T10:00:00.000000000'\n",
      " '2003-12-31T11:00:00.000000000' '2003-12-31T12:00:00.000000000'\n",
      " '2003-12-31T13:00:00.000000000' '2003-12-31T14:00:00.000000000'\n",
      " '2003-12-31T15:00:00.000000000' '2003-12-31T16:00:00.000000000'\n",
      " '2003-12-31T17:00:00.000000000' '2003-12-31T18:00:00.000000000'\n",
      " '2003-12-31T19:00:00.000000000' '2003-12-31T20:00:00.000000000'\n",
      " '2003-12-31T21:00:00.000000000' '2003-12-31T22:00:00.000000000'\n",
      " '2003-12-31T23:00:00.000000000' '2004-01-01T00:00:00.000000000'] (8784 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (366, 24, 3, 4)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.02684009075164795\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 105120 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2003_london_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 8.36 MB\n",
      "📊 Long format sample:\n",
      "          time   step  latitude     longitude  number  surface valid_time  \\\n",
      "276 2002-12-31 1 days      51.6 -2.000000e-01       0      0.0 2003-01-01   \n",
      "277 2002-12-31 1 days      51.6 -1.000000e-01       0      0.0 2003-01-01   \n",
      "278 2002-12-31 1 days      51.6  2.775558e-17       0      0.0 2003-01-01   \n",
      "279 2002-12-31 1 days      51.6  1.000000e-01       0      0.0 2003-01-01   \n",
      "280 2002-12-31 1 days      51.5 -2.000000e-01       0      0.0 2003-01-01   \n",
      "\n",
      "           tp  \n",
      "276  0.000192  \n",
      "277  0.000204  \n",
      "278  0.000219  \n",
      "279  0.000298  \n",
      "280  0.000264  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8760 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2003_london_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time            tp\n",
      "time                                                                         \n",
      "2002-12-31 1 days 00:00:00       0      0.0 2003-01-01 00:00:00  3.267085e-04\n",
      "2003-01-01 0 days 01:00:00       0      0.0 2003-01-01 01:00:00  4.858400e-08\n",
      "2003-01-01 0 days 02:00:00       0      0.0 2003-01-01 02:00:00  1.246827e-04\n",
      "2003-01-01 0 days 03:00:00       0      0.0 2003-01-01 03:00:00  7.476170e-04\n",
      "2003-01-01 0 days 04:00:00       0      0.0 2003-01-01 04:00:00  1.722502e-03\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 288 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2003_london_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.02 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude     longitude  number  surface        tp\n",
      "0 0 days 01:00:00      51.6 -2.000000e-01       0      0.0  0.000039\n",
      "1 0 days 01:00:00      51.6 -1.000000e-01       0      0.0  0.000042\n",
      "2 0 days 01:00:00      51.6  2.775558e-17       0      0.0  0.000045\n",
      "3 0 days 01:00:00      51.6  1.000000e-01       0      0.0  0.000047\n",
      "4 0 days 01:00:00      51.5 -2.000000e-01       0      0.0  0.000041\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2003_london_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2003_london_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2003_london_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 105120 rows\n",
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: ./grib/london_era5land_hourly_tp_2004.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: grib\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: grib\\data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 367, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2003-12-31T00:00:00.000000000 to 2004-12-31T00:00:00.000000000 (367 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 51.4 to 51.6 (3 points)\n",
      "   longitude: -0.2 to 0.1 (4 points)\n",
      "   valid_time: 2003-12-31T01:00:00.000000000 to 2005-01-01T00:00:00.000000000 (8808 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 367, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2003-12-31T00:00:00.000000000 to 2004-12-31T00:00:00.000000000 (367 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: [51.6 51.5 51.4]\n",
      "   longitude: [-2.00000000e-01 -1.00000000e-01  2.77555756e-17  1.00000000e-01]\n",
      "   valid_time: ['2003-12-31T01:00:00.000000000' '2003-12-31T02:00:00.000000000'\n",
      " '2003-12-31T03:00:00.000000000' '2003-12-31T04:00:00.000000000'\n",
      " '2003-12-31T05:00:00.000000000' '2003-12-31T06:00:00.000000000'\n",
      " '2003-12-31T07:00:00.000000000' '2003-12-31T08:00:00.000000000'\n",
      " '2003-12-31T09:00:00.000000000' '2003-12-31T10:00:00.000000000'\n",
      " '2003-12-31T11:00:00.000000000' '2003-12-31T12:00:00.000000000'\n",
      " '2003-12-31T13:00:00.000000000' '2003-12-31T14:00:00.000000000'\n",
      " '2003-12-31T15:00:00.000000000' '2003-12-31T16:00:00.000000000'\n",
      " '2003-12-31T17:00:00.000000000' '2003-12-31T18:00:00.000000000'\n",
      " '2003-12-31T19:00:00.000000000' '2003-12-31T20:00:00.000000000'\n",
      " '2003-12-31T21:00:00.000000000' '2003-12-31T22:00:00.000000000'\n",
      " '2003-12-31T23:00:00.000000000' '2004-01-01T00:00:00.000000000'] to ['2004-12-31T01:00:00.000000000' '2004-12-31T02:00:00.000000000'\n",
      " '2004-12-31T03:00:00.000000000' '2004-12-31T04:00:00.000000000'\n",
      " '2004-12-31T05:00:00.000000000' '2004-12-31T06:00:00.000000000'\n",
      " '2004-12-31T07:00:00.000000000' '2004-12-31T08:00:00.000000000'\n",
      " '2004-12-31T09:00:00.000000000' '2004-12-31T10:00:00.000000000'\n",
      " '2004-12-31T11:00:00.000000000' '2004-12-31T12:00:00.000000000'\n",
      " '2004-12-31T13:00:00.000000000' '2004-12-31T14:00:00.000000000'\n",
      " '2004-12-31T15:00:00.000000000' '2004-12-31T16:00:00.000000000'\n",
      " '2004-12-31T17:00:00.000000000' '2004-12-31T18:00:00.000000000'\n",
      " '2004-12-31T19:00:00.000000000' '2004-12-31T20:00:00.000000000'\n",
      " '2004-12-31T21:00:00.000000000' '2004-12-31T22:00:00.000000000'\n",
      " '2004-12-31T23:00:00.000000000' '2005-01-01T00:00:00.000000000'] (8808 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (367, 24, 3, 4)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.037141475826501846\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 105408 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2004_london_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 8.45 MB\n",
      "📊 Long format sample:\n",
      "          time   step  latitude     longitude  number  surface valid_time  \\\n",
      "276 2003-12-31 1 days      51.6 -2.000000e-01       0      0.0 2004-01-01   \n",
      "277 2003-12-31 1 days      51.6 -1.000000e-01       0      0.0 2004-01-01   \n",
      "278 2003-12-31 1 days      51.6  2.775558e-17       0      0.0 2004-01-01   \n",
      "279 2003-12-31 1 days      51.6  1.000000e-01       0      0.0 2004-01-01   \n",
      "280 2003-12-31 1 days      51.5 -2.000000e-01       0      0.0 2004-01-01   \n",
      "\n",
      "           tp  \n",
      "276  0.000270  \n",
      "277  0.000219  \n",
      "278  0.000172  \n",
      "279  0.000142  \n",
      "280  0.000231  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8784 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2004_london_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time        tp\n",
      "time                                                                     \n",
      "2003-12-31 1 days 00:00:00       0      0.0 2004-01-01 00:00:00  0.000173\n",
      "2004-01-01 0 days 01:00:00       0      0.0 2004-01-01 01:00:00  0.000624\n",
      "2004-01-01 0 days 02:00:00       0      0.0 2004-01-01 02:00:00  0.001771\n",
      "2004-01-01 0 days 03:00:00       0      0.0 2004-01-01 03:00:00  0.003241\n",
      "2004-01-01 0 days 04:00:00       0      0.0 2004-01-01 04:00:00  0.004545\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 288 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2004_london_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.02 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude     longitude  number  surface        tp\n",
      "0 0 days 01:00:00      51.6 -2.000000e-01       0      0.0  0.000041\n",
      "1 0 days 01:00:00      51.6 -1.000000e-01       0      0.0  0.000041\n",
      "2 0 days 01:00:00      51.6  2.775558e-17       0      0.0  0.000041\n",
      "3 0 days 01:00:00      51.6  1.000000e-01       0      0.0  0.000042\n",
      "4 0 days 01:00:00      51.5 -2.000000e-01       0      0.0  0.000041\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2004_london_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2004_london_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2004_london_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 105408 rows\n"
     ]
    }
   ],
   "source": [
    "years = np.arange(2000, 2005)\n",
    "area = 'london'\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    out_file = './grib/' + area + '_era5land_hourly_tp_' + str(year)\n",
    "    grib_file = out_file + '.grib'\n",
    "\n",
    "    file_process = str(year) + '_' + area + '_era5_precipitation'\n",
    "\n",
    "    ds = process_london_precipitation_data(grib_file)\n",
    "        \n",
    "    if ds is not None:\n",
    "        print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "        print(\"\\nTo work with your data:\")\n",
    "        print(\"1. Use ds[variable_name] to access variables\")\n",
    "        print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "        print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "    df = process_my_data(ds, file_process)\n",
    "\n",
    "    for filename in glob.glob(\"./grib/data*\"):\n",
    "        os.remove(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b008fb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c85fb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b770e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d766e49b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf87f837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bffeb36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"./grib/london_era5land_hourly_tp_2014\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2014_puglia_era5_precipitation\")\n",
    "\n",
    "for filename in glob.glob(\"./grib/data*\"):\n",
    "    os.remove(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b682ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"./grib/london_era5land_hourly_tp_2014\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2014_puglia_era5_precipitation\")\n",
    "\n",
    "for filename in glob.glob(\"./grib/data*\"):\n",
    "    os.remove(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc20122",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"./grib/puglia_era5land_hourly_tp_2014\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2014_puglia_era5_precipitation\")\n",
    "\n",
    "for filename in glob.glob(\"./grib/data*\"):\n",
    "    os.remove(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857aa3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"./grib/puglia_era5land_hourly_tp_2013\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2013_puglia_era5_precipitation\")\n",
    "\n",
    "for filename in glob.glob(\"./grib/data*\"):\n",
    "    os.remove(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa31a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"./grib/puglia_era5land_hourly_tp_2012\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2012_puglia_era5_precipitation\")\n",
    "\n",
    "for filename in glob.glob(\"./grib/data*\"):\n",
    "    os.remove(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"./grib/puglia_era5land_hourly_tp_2011\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2011_puglia_era5_precipitation\")\n",
    "\n",
    "for filename in glob.glob(\"./grib/data*\"):\n",
    "    os.remove(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf17455",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"./grib/puglia_era5land_hourly_tp_2010\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2010_puglia_era5_precipitation\")\n",
    "\n",
    "for filename in glob.glob(\"./grib/data*\"):\n",
    "    os.remove(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a4d399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2014\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2014_london_era5_precipitation\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e787a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2013\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2013_london_era5_precipitation\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e488f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2012\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2012_london_era5_precipitation\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6164811",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2011\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2011_london_era5_precipitation\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f4514",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2010\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2010_london_era5_precipitation\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479841e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36adfce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff0ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cea88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25901847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113646be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f54e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1d77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae6093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# puglia_era5land_hourly_tp_2021\n",
    "\n",
    "out_file = \"puglia_era5land_hourly_tp_2021\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2021 = process_my_data(ds, \"2021_puglia_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b77f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e586d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"puglia_era5land_hourly_tp_2022\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2022 = process_my_data(ds, \"2022_puglia_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad46f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb184028",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"puglia_era5land_hourly_tp_2023\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2023 = process_my_data(ds, \"2023_puglia_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8eb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e900d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a04f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# london_era5land_hourly_tp_2020\n",
    "\n",
    "out_file = \"london_era5land_hourly_tp_2020\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2021 = process_my_data(ds, \"2020_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2021.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcec287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b183168",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"puglia_era5land_hourly_tp_2025\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2021 = process_my_data(ds, \"2025_puglia_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c73370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2021\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2021 = process_my_data(ds, \"2021_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c15daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2021.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfef4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b96e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2022\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2022 = process_my_data(ds, \"2022_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be15d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601622e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2025\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2025 = process_my_data(ds, \"2025_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2025 = pd.read_csv('./data/2025_london_era5_precipitation_time_series.csv', comment='#')\n",
    "df_2025.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcccd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2025.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a80599",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2024\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2024 = process_my_data(ds, \"2024_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2023\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2024 = process_my_data(ds, \"2023_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2024.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ceb79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84eaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
