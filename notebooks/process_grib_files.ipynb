{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371cf10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.manage_grib_files import process_london_precipitation_data, process_my_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc20122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: london_era5land_hourly_tp_2019.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: .\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2018-12-31T00:00:00.000000000 to 2019-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 51.4 to 51.6 (3 points)\n",
      "   longitude: -0.2 to 0.1 (4 points)\n",
      "   valid_time: 2018-12-31T01:00:00.000000000 to 2020-01-01T00:00:00.000000000 (8784 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2018-12-31T00:00:00.000000000 to 2019-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: [51.6 51.5 51.4]\n",
      "   longitude: [-2.00000000e-01 -1.00000000e-01  2.77555756e-17  1.00000000e-01]\n",
      "   valid_time: ['2018-12-31T01:00:00.000000000' '2018-12-31T02:00:00.000000000'\n",
      " '2018-12-31T03:00:00.000000000' '2018-12-31T04:00:00.000000000'\n",
      " '2018-12-31T05:00:00.000000000' '2018-12-31T06:00:00.000000000'\n",
      " '2018-12-31T07:00:00.000000000' '2018-12-31T08:00:00.000000000'\n",
      " '2018-12-31T09:00:00.000000000' '2018-12-31T10:00:00.000000000'\n",
      " '2018-12-31T11:00:00.000000000' '2018-12-31T12:00:00.000000000'\n",
      " '2018-12-31T13:00:00.000000000' '2018-12-31T14:00:00.000000000'\n",
      " '2018-12-31T15:00:00.000000000' '2018-12-31T16:00:00.000000000'\n",
      " '2018-12-31T17:00:00.000000000' '2018-12-31T18:00:00.000000000'\n",
      " '2018-12-31T19:00:00.000000000' '2018-12-31T20:00:00.000000000'\n",
      " '2018-12-31T21:00:00.000000000' '2018-12-31T22:00:00.000000000'\n",
      " '2018-12-31T23:00:00.000000000' '2019-01-01T00:00:00.000000000'] to ['2019-12-31T01:00:00.000000000' '2019-12-31T02:00:00.000000000'\n",
      " '2019-12-31T03:00:00.000000000' '2019-12-31T04:00:00.000000000'\n",
      " '2019-12-31T05:00:00.000000000' '2019-12-31T06:00:00.000000000'\n",
      " '2019-12-31T07:00:00.000000000' '2019-12-31T08:00:00.000000000'\n",
      " '2019-12-31T09:00:00.000000000' '2019-12-31T10:00:00.000000000'\n",
      " '2019-12-31T11:00:00.000000000' '2019-12-31T12:00:00.000000000'\n",
      " '2019-12-31T13:00:00.000000000' '2019-12-31T14:00:00.000000000'\n",
      " '2019-12-31T15:00:00.000000000' '2019-12-31T16:00:00.000000000'\n",
      " '2019-12-31T17:00:00.000000000' '2019-12-31T18:00:00.000000000'\n",
      " '2019-12-31T19:00:00.000000000' '2019-12-31T20:00:00.000000000'\n",
      " '2019-12-31T21:00:00.000000000' '2019-12-31T22:00:00.000000000'\n",
      " '2019-12-31T23:00:00.000000000' '2020-01-01T00:00:00.000000000'] (8784 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (366, 24, 3, 4)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.030677393078804016\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 105120 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2019_london_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 8.39 MB\n",
      "📊 Long format sample:\n",
      "          time   step  latitude     longitude  number  surface valid_time  \\\n",
      "276 2018-12-31 1 days      51.6 -2.000000e-01       0      0.0 2019-01-01   \n",
      "277 2018-12-31 1 days      51.6 -1.000000e-01       0      0.0 2019-01-01   \n",
      "278 2018-12-31 1 days      51.6  2.775558e-17       0      0.0 2019-01-01   \n",
      "279 2018-12-31 1 days      51.6  1.000000e-01       0      0.0 2019-01-01   \n",
      "280 2018-12-31 1 days      51.5 -2.000000e-01       0      0.0 2019-01-01   \n",
      "\n",
      "           tp  \n",
      "276  0.000163  \n",
      "277  0.000167  \n",
      "278  0.000168  \n",
      "279  0.000174  \n",
      "280  0.000188  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8760 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2019_london_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time        tp\n",
      "time                                                                     \n",
      "2018-12-31 1 days 00:00:00       0      0.0 2019-01-01 00:00:00  0.000194\n",
      "2019-01-01 0 days 01:00:00       0      0.0 2019-01-01 01:00:00  0.000001\n",
      "2019-01-01 0 days 02:00:00       0      0.0 2019-01-01 02:00:00  0.000001\n",
      "2019-01-01 0 days 03:00:00       0      0.0 2019-01-01 03:00:00  0.000001\n",
      "2019-01-01 0 days 04:00:00       0      0.0 2019-01-01 04:00:00  0.000001\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 288 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2019_london_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.02 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude     longitude  number  surface        tp\n",
      "0 0 days 01:00:00      51.6 -2.000000e-01       0      0.0  0.000086\n",
      "1 0 days 01:00:00      51.6 -1.000000e-01       0      0.0  0.000084\n",
      "2 0 days 01:00:00      51.6  2.775558e-17       0      0.0  0.000082\n",
      "3 0 days 01:00:00      51.6  1.000000e-01       0      0.0  0.000082\n",
      "4 0 days 01:00:00      51.5 -2.000000e-01       0      0.0  0.000087\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2019_london_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2019_london_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2019_london_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 105120 rows\n"
     ]
    }
   ],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2019\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df = process_my_data(ds, \"2019_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1d77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae6093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749b687f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: puglia_era5land_hourly_tp_2021.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: .\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 366, 'step': 24, 'latitude': 18, 'longitude': 33}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2020-12-31T00:00:00.000000000 to 2021-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 40.2 to 41.9 (18 points)\n",
      "   longitude: 15.3 to 18.5 (33 points)\n",
      "   valid_time: 2020-12-31T01:00:00.000000000 to 2022-01-01T00:00:00.000000000 (8784 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 366, 'step': 24, 'latitude': 18, 'longitude': 33}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2020-12-31T00:00:00.000000000 to 2021-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 41.9 to 40.2 (18 points)\n",
      "   longitude: 15.3 to 18.5 (33 points)\n",
      "   valid_time: ['2020-12-31T01:00:00.000000000' '2020-12-31T02:00:00.000000000'\n",
      " '2020-12-31T03:00:00.000000000' '2020-12-31T04:00:00.000000000'\n",
      " '2020-12-31T05:00:00.000000000' '2020-12-31T06:00:00.000000000'\n",
      " '2020-12-31T07:00:00.000000000' '2020-12-31T08:00:00.000000000'\n",
      " '2020-12-31T09:00:00.000000000' '2020-12-31T10:00:00.000000000'\n",
      " '2020-12-31T11:00:00.000000000' '2020-12-31T12:00:00.000000000'\n",
      " '2020-12-31T13:00:00.000000000' '2020-12-31T14:00:00.000000000'\n",
      " '2020-12-31T15:00:00.000000000' '2020-12-31T16:00:00.000000000'\n",
      " '2020-12-31T17:00:00.000000000' '2020-12-31T18:00:00.000000000'\n",
      " '2020-12-31T19:00:00.000000000' '2020-12-31T20:00:00.000000000'\n",
      " '2020-12-31T21:00:00.000000000' '2020-12-31T22:00:00.000000000'\n",
      " '2020-12-31T23:00:00.000000000' '2021-01-01T00:00:00.000000000'] to ['2021-12-31T01:00:00.000000000' '2021-12-31T02:00:00.000000000'\n",
      " '2021-12-31T03:00:00.000000000' '2021-12-31T04:00:00.000000000'\n",
      " '2021-12-31T05:00:00.000000000' '2021-12-31T06:00:00.000000000'\n",
      " '2021-12-31T07:00:00.000000000' '2021-12-31T08:00:00.000000000'\n",
      " '2021-12-31T09:00:00.000000000' '2021-12-31T10:00:00.000000000'\n",
      " '2021-12-31T11:00:00.000000000' '2021-12-31T12:00:00.000000000'\n",
      " '2021-12-31T13:00:00.000000000' '2021-12-31T14:00:00.000000000'\n",
      " '2021-12-31T15:00:00.000000000' '2021-12-31T16:00:00.000000000'\n",
      " '2021-12-31T17:00:00.000000000' '2021-12-31T18:00:00.000000000'\n",
      " '2021-12-31T19:00:00.000000000' '2021-12-31T20:00:00.000000000'\n",
      " '2021-12-31T21:00:00.000000000' '2021-12-31T22:00:00.000000000'\n",
      " '2021-12-31T23:00:00.000000000' '2022-01-01T00:00:00.000000000'] (8784 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (366, 24, 18, 33)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.05211973190307617\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 2680560 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2021_puglia_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 243.05 MB\n",
      "📊 Long format sample:\n",
      "            time   step  latitude  longitude  number  surface valid_time  \\\n",
      "13663 2020-12-31 1 days      41.9       15.4       0      0.0 2021-01-01   \n",
      "13664 2020-12-31 1 days      41.9       15.5       0      0.0 2021-01-01   \n",
      "13667 2020-12-31 1 days      41.9       15.8       0      0.0 2021-01-01   \n",
      "13668 2020-12-31 1 days      41.9       15.9       0      0.0 2021-01-01   \n",
      "13669 2020-12-31 1 days      41.9       16.0       0      0.0 2021-01-01   \n",
      "\n",
      "             tp  \n",
      "13663  0.002429  \n",
      "13664  0.002445  \n",
      "13667  0.004885  \n",
      "13668  0.004713  \n",
      "13669  0.005022  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8760 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2021_puglia_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time        tp\n",
      "time                                                                     \n",
      "2020-12-31 1 days 00:00:00       0      0.0 2021-01-01 00:00:00  0.000777\n",
      "2021-01-01 0 days 01:00:00       0      0.0 2021-01-01 01:00:00  0.000003\n",
      "2021-01-01 0 days 02:00:00       0      0.0 2021-01-01 02:00:00  0.000005\n",
      "2021-01-01 0 days 03:00:00       0      0.0 2021-01-01 03:00:00  0.000007\n",
      "2021-01-01 0 days 04:00:00       0      0.0 2021-01-01 04:00:00  0.000008\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 7344 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2021_puglia_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.47 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude  longitude  number  surface        tp\n",
      "1 0 days 01:00:00      41.9       15.4       0      0.0  0.000060\n",
      "2 0 days 01:00:00      41.9       15.5       0      0.0  0.000065\n",
      "5 0 days 01:00:00      41.9       15.8       0      0.0  0.000081\n",
      "6 0 days 01:00:00      41.9       15.9       0      0.0  0.000079\n",
      "7 0 days 01:00:00      41.9       16.0       0      0.0  0.000077\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2021_puglia_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2021_puglia_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2021_puglia_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 2680560 rows\n"
     ]
    }
   ],
   "source": [
    "# puglia_era5land_hourly_tp_2021\n",
    "\n",
    "out_file = \"puglia_era5land_hourly_tp_2021\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2021 = process_my_data(ds, \"2021_puglia_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b77f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e586d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: puglia_era5land_hourly_tp_2022.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: .\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 366, 'step': 24, 'latitude': 18, 'longitude': 33}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2021-12-31T00:00:00.000000000 to 2022-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 40.2 to 41.9 (18 points)\n",
      "   longitude: 15.3 to 18.5 (33 points)\n",
      "   valid_time: 2021-12-31T01:00:00.000000000 to 2023-01-01T00:00:00.000000000 (8784 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 366, 'step': 24, 'latitude': 18, 'longitude': 33}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2021-12-31T00:00:00.000000000 to 2022-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 41.9 to 40.2 (18 points)\n",
      "   longitude: 15.3 to 18.5 (33 points)\n",
      "   valid_time: ['2021-12-31T01:00:00.000000000' '2021-12-31T02:00:00.000000000'\n",
      " '2021-12-31T03:00:00.000000000' '2021-12-31T04:00:00.000000000'\n",
      " '2021-12-31T05:00:00.000000000' '2021-12-31T06:00:00.000000000'\n",
      " '2021-12-31T07:00:00.000000000' '2021-12-31T08:00:00.000000000'\n",
      " '2021-12-31T09:00:00.000000000' '2021-12-31T10:00:00.000000000'\n",
      " '2021-12-31T11:00:00.000000000' '2021-12-31T12:00:00.000000000'\n",
      " '2021-12-31T13:00:00.000000000' '2021-12-31T14:00:00.000000000'\n",
      " '2021-12-31T15:00:00.000000000' '2021-12-31T16:00:00.000000000'\n",
      " '2021-12-31T17:00:00.000000000' '2021-12-31T18:00:00.000000000'\n",
      " '2021-12-31T19:00:00.000000000' '2021-12-31T20:00:00.000000000'\n",
      " '2021-12-31T21:00:00.000000000' '2021-12-31T22:00:00.000000000'\n",
      " '2021-12-31T23:00:00.000000000' '2022-01-01T00:00:00.000000000'] to ['2022-12-31T01:00:00.000000000' '2022-12-31T02:00:00.000000000'\n",
      " '2022-12-31T03:00:00.000000000' '2022-12-31T04:00:00.000000000'\n",
      " '2022-12-31T05:00:00.000000000' '2022-12-31T06:00:00.000000000'\n",
      " '2022-12-31T07:00:00.000000000' '2022-12-31T08:00:00.000000000'\n",
      " '2022-12-31T09:00:00.000000000' '2022-12-31T10:00:00.000000000'\n",
      " '2022-12-31T11:00:00.000000000' '2022-12-31T12:00:00.000000000'\n",
      " '2022-12-31T13:00:00.000000000' '2022-12-31T14:00:00.000000000'\n",
      " '2022-12-31T15:00:00.000000000' '2022-12-31T16:00:00.000000000'\n",
      " '2022-12-31T17:00:00.000000000' '2022-12-31T18:00:00.000000000'\n",
      " '2022-12-31T19:00:00.000000000' '2022-12-31T20:00:00.000000000'\n",
      " '2022-12-31T21:00:00.000000000' '2022-12-31T22:00:00.000000000'\n",
      " '2022-12-31T23:00:00.000000000' '2023-01-01T00:00:00.000000000'] (8784 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (366, 24, 18, 33)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.07606635987758636\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 2680560 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 202_puglia_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 242.65 MB\n",
      "📊 Long format sample:\n",
      "            time   step  latitude  longitude  number  surface valid_time  \\\n",
      "13663 2021-12-31 1 days      41.9       15.4       0      0.0 2022-01-01   \n",
      "13664 2021-12-31 1 days      41.9       15.5       0      0.0 2022-01-01   \n",
      "13667 2021-12-31 1 days      41.9       15.8       0      0.0 2022-01-01   \n",
      "13668 2021-12-31 1 days      41.9       15.9       0      0.0 2022-01-01   \n",
      "13669 2021-12-31 1 days      41.9       16.0       0      0.0 2022-01-01   \n",
      "\n",
      "                 tp  \n",
      "13663  8.523463e-07  \n",
      "13664  8.523463e-07  \n",
      "13667  2.580881e-06  \n",
      "13668  2.789497e-06  \n",
      "13669  2.700090e-06  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8760 rows and 5 columns\n",
      "💾 Saving DataFrame to: 202_puglia_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time        tp\n",
      "time                                                                     \n",
      "2021-12-31 1 days 00:00:00       0      0.0 2022-01-01 00:00:00  0.000003\n",
      "2022-01-01 0 days 01:00:00       0      0.0 2022-01-01 01:00:00  0.000000\n",
      "2022-01-01 0 days 02:00:00       0      0.0 2022-01-01 02:00:00  0.000000\n",
      "2022-01-01 0 days 03:00:00       0      0.0 2022-01-01 03:00:00  0.000000\n",
      "2022-01-01 0 days 04:00:00       0      0.0 2022-01-01 04:00:00  0.000000\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 7344 rows and 6 columns\n",
      "💾 Saving DataFrame to: 202_puglia_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.47 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude  longitude  number  surface        tp\n",
      "1 0 days 01:00:00      41.9       15.4       0      0.0  0.000051\n",
      "2 0 days 01:00:00      41.9       15.5       0      0.0  0.000049\n",
      "5 0 days 01:00:00      41.9       15.8       0      0.0  0.000048\n",
      "6 0 days 01:00:00      41.9       15.9       0      0.0  0.000045\n",
      "7 0 days 01:00:00      41.9       16.0       0      0.0  0.000044\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 202_puglia_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 202_puglia_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 202_puglia_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 2680560 rows\n"
     ]
    }
   ],
   "source": [
    "out_file = \"puglia_era5land_hourly_tp_2022\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2022 = process_my_data(ds, \"2022_puglia_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad46f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb184028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: puglia_era5land_hourly_tp_2023.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: .\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 366, 'step': 24, 'latitude': 18, 'longitude': 33}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2022-12-31T00:00:00.000000000 to 2023-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 40.2 to 41.9 (18 points)\n",
      "   longitude: 15.3 to 18.5 (33 points)\n",
      "   valid_time: 2022-12-31T01:00:00.000000000 to 2024-01-01T00:00:00.000000000 (8784 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 366, 'step': 24, 'latitude': 18, 'longitude': 33}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2022-12-31T00:00:00.000000000 to 2023-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 41.9 to 40.2 (18 points)\n",
      "   longitude: 15.3 to 18.5 (33 points)\n",
      "   valid_time: ['2022-12-31T01:00:00.000000000' '2022-12-31T02:00:00.000000000'\n",
      " '2022-12-31T03:00:00.000000000' '2022-12-31T04:00:00.000000000'\n",
      " '2022-12-31T05:00:00.000000000' '2022-12-31T06:00:00.000000000'\n",
      " '2022-12-31T07:00:00.000000000' '2022-12-31T08:00:00.000000000'\n",
      " '2022-12-31T09:00:00.000000000' '2022-12-31T10:00:00.000000000'\n",
      " '2022-12-31T11:00:00.000000000' '2022-12-31T12:00:00.000000000'\n",
      " '2022-12-31T13:00:00.000000000' '2022-12-31T14:00:00.000000000'\n",
      " '2022-12-31T15:00:00.000000000' '2022-12-31T16:00:00.000000000'\n",
      " '2022-12-31T17:00:00.000000000' '2022-12-31T18:00:00.000000000'\n",
      " '2022-12-31T19:00:00.000000000' '2022-12-31T20:00:00.000000000'\n",
      " '2022-12-31T21:00:00.000000000' '2022-12-31T22:00:00.000000000'\n",
      " '2022-12-31T23:00:00.000000000' '2023-01-01T00:00:00.000000000'] to ['2023-12-31T01:00:00.000000000' '2023-12-31T02:00:00.000000000'\n",
      " '2023-12-31T03:00:00.000000000' '2023-12-31T04:00:00.000000000'\n",
      " '2023-12-31T05:00:00.000000000' '2023-12-31T06:00:00.000000000'\n",
      " '2023-12-31T07:00:00.000000000' '2023-12-31T08:00:00.000000000'\n",
      " '2023-12-31T09:00:00.000000000' '2023-12-31T10:00:00.000000000'\n",
      " '2023-12-31T11:00:00.000000000' '2023-12-31T12:00:00.000000000'\n",
      " '2023-12-31T13:00:00.000000000' '2023-12-31T14:00:00.000000000'\n",
      " '2023-12-31T15:00:00.000000000' '2023-12-31T16:00:00.000000000'\n",
      " '2023-12-31T17:00:00.000000000' '2023-12-31T18:00:00.000000000'\n",
      " '2023-12-31T19:00:00.000000000' '2023-12-31T20:00:00.000000000'\n",
      " '2023-12-31T21:00:00.000000000' '2023-12-31T22:00:00.000000000'\n",
      " '2023-12-31T23:00:00.000000000' '2024-01-01T00:00:00.000000000'] (8784 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (366, 24, 18, 33)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.08309638500213623\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 2680560 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2023_puglia_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 243.25 MB\n",
      "📊 Long format sample:\n",
      "            time   step  latitude  longitude  number  surface valid_time  \\\n",
      "13663 2022-12-31 1 days      41.9       15.4       0      0.0 2023-01-01   \n",
      "13664 2022-12-31 1 days      41.9       15.5       0      0.0 2023-01-01   \n",
      "13667 2022-12-31 1 days      41.9       15.8       0      0.0 2023-01-01   \n",
      "13668 2022-12-31 1 days      41.9       15.9       0      0.0 2023-01-01   \n",
      "13669 2022-12-31 1 days      41.9       16.0       0      0.0 2023-01-01   \n",
      "\n",
      "             tp  \n",
      "13663  0.000002  \n",
      "13664  0.000002  \n",
      "13667  0.000002  \n",
      "13668  0.000002  \n",
      "13669  0.000002  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8760 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2023_puglia_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time            tp\n",
      "time                                                                         \n",
      "2022-12-31 1 days 00:00:00       0      0.0 2023-01-01 00:00:00  1.051227e-05\n",
      "2023-01-01 0 days 01:00:00       0      0.0 2023-01-01 01:00:00  0.000000e+00\n",
      "2023-01-01 0 days 02:00:00       0      0.0 2023-01-01 02:00:00  0.000000e+00\n",
      "2023-01-01 0 days 03:00:00       0      0.0 2023-01-01 03:00:00  3.579200e-09\n",
      "2023-01-01 0 days 04:00:00       0      0.0 2023-01-01 04:00:00  3.476937e-08\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 7344 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2023_puglia_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.47 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude  longitude  number  surface        tp\n",
      "1 0 days 01:00:00      41.9       15.4       0      0.0  0.000070\n",
      "2 0 days 01:00:00      41.9       15.5       0      0.0  0.000074\n",
      "5 0 days 01:00:00      41.9       15.8       0      0.0  0.000081\n",
      "6 0 days 01:00:00      41.9       15.9       0      0.0  0.000074\n",
      "7 0 days 01:00:00      41.9       16.0       0      0.0  0.000072\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2023_puglia_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2023_puglia_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2023_puglia_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 2680560 rows\n"
     ]
    }
   ],
   "source": [
    "out_file = \"puglia_era5land_hourly_tp_2023\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2023 = process_my_data(ds, \"2023_puglia_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8eb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e900d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a04f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: london_era5land_hourly_tp_2020.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: .\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 367, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2019-12-31T00:00:00.000000000 to 2020-12-31T00:00:00.000000000 (367 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 51.4 to 51.6 (3 points)\n",
      "   longitude: -0.2 to 0.1 (4 points)\n",
      "   valid_time: 2019-12-31T01:00:00.000000000 to 2021-01-01T00:00:00.000000000 (8808 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 367, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2019-12-31T00:00:00.000000000 to 2020-12-31T00:00:00.000000000 (367 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: [51.6 51.5 51.4]\n",
      "   longitude: [-2.00000000e-01 -1.00000000e-01  2.77555756e-17  1.00000000e-01]\n",
      "   valid_time: ['2019-12-31T01:00:00.000000000' '2019-12-31T02:00:00.000000000'\n",
      " '2019-12-31T03:00:00.000000000' '2019-12-31T04:00:00.000000000'\n",
      " '2019-12-31T05:00:00.000000000' '2019-12-31T06:00:00.000000000'\n",
      " '2019-12-31T07:00:00.000000000' '2019-12-31T08:00:00.000000000'\n",
      " '2019-12-31T09:00:00.000000000' '2019-12-31T10:00:00.000000000'\n",
      " '2019-12-31T11:00:00.000000000' '2019-12-31T12:00:00.000000000'\n",
      " '2019-12-31T13:00:00.000000000' '2019-12-31T14:00:00.000000000'\n",
      " '2019-12-31T15:00:00.000000000' '2019-12-31T16:00:00.000000000'\n",
      " '2019-12-31T17:00:00.000000000' '2019-12-31T18:00:00.000000000'\n",
      " '2019-12-31T19:00:00.000000000' '2019-12-31T20:00:00.000000000'\n",
      " '2019-12-31T21:00:00.000000000' '2019-12-31T22:00:00.000000000'\n",
      " '2019-12-31T23:00:00.000000000' '2020-01-01T00:00:00.000000000'] to ['2020-12-31T01:00:00.000000000' '2020-12-31T02:00:00.000000000'\n",
      " '2020-12-31T03:00:00.000000000' '2020-12-31T04:00:00.000000000'\n",
      " '2020-12-31T05:00:00.000000000' '2020-12-31T06:00:00.000000000'\n",
      " '2020-12-31T07:00:00.000000000' '2020-12-31T08:00:00.000000000'\n",
      " '2020-12-31T09:00:00.000000000' '2020-12-31T10:00:00.000000000'\n",
      " '2020-12-31T11:00:00.000000000' '2020-12-31T12:00:00.000000000'\n",
      " '2020-12-31T13:00:00.000000000' '2020-12-31T14:00:00.000000000'\n",
      " '2020-12-31T15:00:00.000000000' '2020-12-31T16:00:00.000000000'\n",
      " '2020-12-31T17:00:00.000000000' '2020-12-31T18:00:00.000000000'\n",
      " '2020-12-31T19:00:00.000000000' '2020-12-31T20:00:00.000000000'\n",
      " '2020-12-31T21:00:00.000000000' '2020-12-31T22:00:00.000000000'\n",
      " '2020-12-31T23:00:00.000000000' '2021-01-01T00:00:00.000000000'] (8808 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (367, 24, 3, 4)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.022458001971244812\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 105408 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2020_london_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 8.38 MB\n",
      "📊 Long format sample:\n",
      "          time   step  latitude     longitude  number  surface valid_time  \\\n",
      "276 2019-12-31 1 days      51.6 -2.000000e-01       0      0.0 2020-01-01   \n",
      "277 2019-12-31 1 days      51.6 -1.000000e-01       0      0.0 2020-01-01   \n",
      "278 2019-12-31 1 days      51.6  2.775558e-17       0      0.0 2020-01-01   \n",
      "279 2019-12-31 1 days      51.6  1.000000e-01       0      0.0 2020-01-01   \n",
      "280 2019-12-31 1 days      51.5 -2.000000e-01       0      0.0 2020-01-01   \n",
      "\n",
      "           tp  \n",
      "276  0.000048  \n",
      "277  0.000044  \n",
      "278  0.000041  \n",
      "279  0.000043  \n",
      "280  0.000043  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8784 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2020_london_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time        tp\n",
      "time                                                                     \n",
      "2019-12-31 1 days 00:00:00       0      0.0 2020-01-01 00:00:00  0.000037\n",
      "2020-01-01 0 days 01:00:00       0      0.0 2020-01-01 01:00:00  0.000001\n",
      "2020-01-01 0 days 02:00:00       0      0.0 2020-01-01 02:00:00  0.000006\n",
      "2020-01-01 0 days 03:00:00       0      0.0 2020-01-01 03:00:00  0.000011\n",
      "2020-01-01 0 days 04:00:00       0      0.0 2020-01-01 04:00:00  0.000015\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 288 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2020_london_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.02 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude     longitude  number  surface        tp\n",
      "0 0 days 01:00:00      51.6 -2.000000e-01       0      0.0  0.000064\n",
      "1 0 days 01:00:00      51.6 -1.000000e-01       0      0.0  0.000063\n",
      "2 0 days 01:00:00      51.6  2.775558e-17       0      0.0  0.000062\n",
      "3 0 days 01:00:00      51.6  1.000000e-01       0      0.0  0.000062\n",
      "4 0 days 01:00:00      51.5 -2.000000e-01       0      0.0  0.000065\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2020_london_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2020_london_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2020_london_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 105408 rows\n"
     ]
    }
   ],
   "source": [
    "# london_era5land_hourly_tp_2020\n",
    "\n",
    "out_file = \"london_era5land_hourly_tp_2020\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2021 = process_my_data(ds, \"2020_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349c5240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>step</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>number</th>\n",
       "      <th>surface</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105403</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.5</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-31 23:00:00</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105404</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>-2.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-31 23:00:00</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105405</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-31 23:00:00</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105406</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-31 23:00:00</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105407</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-12-31 23:00:00</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              time             step  latitude     longitude  number  surface  \\\n",
       "105403  2020-12-31  0 days 23:00:00      51.5  1.000000e-01       0      0.0   \n",
       "105404  2020-12-31  0 days 23:00:00      51.4 -2.000000e-01       0      0.0   \n",
       "105405  2020-12-31  0 days 23:00:00      51.4 -1.000000e-01       0      0.0   \n",
       "105406  2020-12-31  0 days 23:00:00      51.4  2.775558e-17       0      0.0   \n",
       "105407  2020-12-31  0 days 23:00:00      51.4  1.000000e-01       0      0.0   \n",
       "\n",
       "                 valid_time        tp  \n",
       "105403  2020-12-31 23:00:00  0.000009  \n",
       "105404  2020-12-31 23:00:00  0.000017  \n",
       "105405  2020-12-31 23:00:00  0.000016  \n",
       "105406  2020-12-31 23:00:00  0.000014  \n",
       "105407  2020-12-31 23:00:00  0.000014  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2021.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcec287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b183168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: puglia_era5land_hourly_tp_2025.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: .\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 180, 'step': 24, 'latitude': 18, 'longitude': 33}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2024-12-31T00:00:00.000000000 to 2025-06-28T00:00:00.000000000 (180 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 40.2 to 41.9 (18 points)\n",
      "   longitude: 15.3 to 18.5 (33 points)\n",
      "   valid_time: 2024-12-31T01:00:00.000000000 to 2025-06-29T00:00:00.000000000 (4320 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 180, 'step': 24, 'latitude': 18, 'longitude': 33}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2024-12-31T00:00:00.000000000 to 2025-06-28T00:00:00.000000000 (180 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 41.9 to 40.2 (18 points)\n",
      "   longitude: 15.3 to 18.5 (33 points)\n",
      "   valid_time: ['2024-12-31T01:00:00.000000000' '2024-12-31T02:00:00.000000000'\n",
      " '2024-12-31T03:00:00.000000000' '2024-12-31T04:00:00.000000000'\n",
      " '2024-12-31T05:00:00.000000000' '2024-12-31T06:00:00.000000000'\n",
      " '2024-12-31T07:00:00.000000000' '2024-12-31T08:00:00.000000000'\n",
      " '2024-12-31T09:00:00.000000000' '2024-12-31T10:00:00.000000000'\n",
      " '2024-12-31T11:00:00.000000000' '2024-12-31T12:00:00.000000000'\n",
      " '2024-12-31T13:00:00.000000000' '2024-12-31T14:00:00.000000000'\n",
      " '2024-12-31T15:00:00.000000000' '2024-12-31T16:00:00.000000000'\n",
      " '2024-12-31T17:00:00.000000000' '2024-12-31T18:00:00.000000000'\n",
      " '2024-12-31T19:00:00.000000000' '2024-12-31T20:00:00.000000000'\n",
      " '2024-12-31T21:00:00.000000000' '2024-12-31T22:00:00.000000000'\n",
      " '2024-12-31T23:00:00.000000000' '2025-01-01T00:00:00.000000000'] to ['2025-06-28T01:00:00.000000000' '2025-06-28T02:00:00.000000000'\n",
      " '2025-06-28T03:00:00.000000000' '2025-06-28T04:00:00.000000000'\n",
      " '2025-06-28T05:00:00.000000000' '2025-06-28T06:00:00.000000000'\n",
      " '2025-06-28T07:00:00.000000000' '2025-06-28T08:00:00.000000000'\n",
      " '2025-06-28T09:00:00.000000000' '2025-06-28T10:00:00.000000000'\n",
      " '2025-06-28T11:00:00.000000000' '2025-06-28T12:00:00.000000000'\n",
      " '2025-06-28T13:00:00.000000000' '2025-06-28T14:00:00.000000000'\n",
      " '2025-06-28T15:00:00.000000000' '2025-06-28T16:00:00.000000000'\n",
      " '2025-06-28T17:00:00.000000000' '2025-06-28T18:00:00.000000000'\n",
      " '2025-06-28T19:00:00.000000000' '2025-06-28T20:00:00.000000000'\n",
      " '2025-06-28T21:00:00.000000000' '2025-06-28T22:00:00.000000000'\n",
      " '2025-06-28T23:00:00.000000000' '2025-06-29T00:00:00.000000000'] (4320 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (180, 24, 18, 33)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.053033072501420975\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 1308762 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2025_puglia_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 118.62 MB\n",
      "📊 Long format sample:\n",
      "            time   step  latitude  longitude  number  surface valid_time   tp\n",
      "13663 2024-12-31 1 days      41.9       15.4       0      0.0 2025-01-01  0.0\n",
      "13664 2024-12-31 1 days      41.9       15.5       0      0.0 2025-01-01  0.0\n",
      "13667 2024-12-31 1 days      41.9       15.8       0      0.0 2025-01-01  0.0\n",
      "13668 2024-12-31 1 days      41.9       15.9       0      0.0 2025-01-01  0.0\n",
      "13669 2024-12-31 1 days      41.9       16.0       0      0.0 2025-01-01  0.0\n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 4277 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2025_puglia_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.23 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time            tp\n",
      "time                                                                         \n",
      "2024-12-31 1 days 00:00:00       0      0.0 2025-01-01 00:00:00  6.712340e-07\n",
      "2025-01-01 0 days 01:00:00       0      0.0 2025-01-01 01:00:00  4.439913e-08\n",
      "2025-01-01 0 days 02:00:00       0      0.0 2025-01-01 02:00:00  6.542389e-08\n",
      "2025-01-01 0 days 03:00:00       0      0.0 2025-01-01 03:00:00  1.182110e-07\n",
      "2025-01-01 0 days 04:00:00       0      0.0 2025-01-01 04:00:00  1.990961e-07\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 7344 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2025_puglia_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.47 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude  longitude  number  surface        tp\n",
      "1 0 days 01:00:00      41.9       15.4       0      0.0  0.000053\n",
      "2 0 days 01:00:00      41.9       15.5       0      0.0  0.000058\n",
      "5 0 days 01:00:00      41.9       15.8       0      0.0  0.000065\n",
      "6 0 days 01:00:00      41.9       15.9       0      0.0  0.000063\n",
      "7 0 days 01:00:00      41.9       16.0       0      0.0  0.000063\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2025_puglia_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2025_puglia_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2025_puglia_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 1308762 rows\n"
     ]
    }
   ],
   "source": [
    "out_file = \"puglia_era5land_hourly_tp_2025\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2021 = process_my_data(ds, \"2025_puglia_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c73370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f9c272e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: london_era5land_hourly_tp_2021.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: .\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2020-12-31T00:00:00.000000000 to 2021-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 51.4 to 51.6 (3 points)\n",
      "   longitude: -0.2 to 0.1 (4 points)\n",
      "   valid_time: 2020-12-31T01:00:00.000000000 to 2022-01-01T00:00:00.000000000 (8784 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2020-12-31T00:00:00.000000000 to 2021-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: [51.6 51.5 51.4]\n",
      "   longitude: [-2.00000000e-01 -1.00000000e-01  2.77555756e-17  1.00000000e-01]\n",
      "   valid_time: ['2020-12-31T01:00:00.000000000' '2020-12-31T02:00:00.000000000'\n",
      " '2020-12-31T03:00:00.000000000' '2020-12-31T04:00:00.000000000'\n",
      " '2020-12-31T05:00:00.000000000' '2020-12-31T06:00:00.000000000'\n",
      " '2020-12-31T07:00:00.000000000' '2020-12-31T08:00:00.000000000'\n",
      " '2020-12-31T09:00:00.000000000' '2020-12-31T10:00:00.000000000'\n",
      " '2020-12-31T11:00:00.000000000' '2020-12-31T12:00:00.000000000'\n",
      " '2020-12-31T13:00:00.000000000' '2020-12-31T14:00:00.000000000'\n",
      " '2020-12-31T15:00:00.000000000' '2020-12-31T16:00:00.000000000'\n",
      " '2020-12-31T17:00:00.000000000' '2020-12-31T18:00:00.000000000'\n",
      " '2020-12-31T19:00:00.000000000' '2020-12-31T20:00:00.000000000'\n",
      " '2020-12-31T21:00:00.000000000' '2020-12-31T22:00:00.000000000'\n",
      " '2020-12-31T23:00:00.000000000' '2021-01-01T00:00:00.000000000'] to ['2021-12-31T01:00:00.000000000' '2021-12-31T02:00:00.000000000'\n",
      " '2021-12-31T03:00:00.000000000' '2021-12-31T04:00:00.000000000'\n",
      " '2021-12-31T05:00:00.000000000' '2021-12-31T06:00:00.000000000'\n",
      " '2021-12-31T07:00:00.000000000' '2021-12-31T08:00:00.000000000'\n",
      " '2021-12-31T09:00:00.000000000' '2021-12-31T10:00:00.000000000'\n",
      " '2021-12-31T11:00:00.000000000' '2021-12-31T12:00:00.000000000'\n",
      " '2021-12-31T13:00:00.000000000' '2021-12-31T14:00:00.000000000'\n",
      " '2021-12-31T15:00:00.000000000' '2021-12-31T16:00:00.000000000'\n",
      " '2021-12-31T17:00:00.000000000' '2021-12-31T18:00:00.000000000'\n",
      " '2021-12-31T19:00:00.000000000' '2021-12-31T20:00:00.000000000'\n",
      " '2021-12-31T21:00:00.000000000' '2021-12-31T22:00:00.000000000'\n",
      " '2021-12-31T23:00:00.000000000' '2022-01-01T00:00:00.000000000'] (8784 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (366, 24, 3, 4)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.0361451655626297\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 105120 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2021_london_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 8.42 MB\n",
      "📊 Long format sample:\n",
      "          time   step  latitude     longitude  number  surface valid_time  \\\n",
      "276 2020-12-31 1 days      51.6 -2.000000e-01       0      0.0 2021-01-01   \n",
      "277 2020-12-31 1 days      51.6 -1.000000e-01       0      0.0 2021-01-01   \n",
      "278 2020-12-31 1 days      51.6  2.775558e-17       0      0.0 2021-01-01   \n",
      "279 2020-12-31 1 days      51.6  1.000000e-01       0      0.0 2021-01-01   \n",
      "280 2020-12-31 1 days      51.5 -2.000000e-01       0      0.0 2021-01-01   \n",
      "\n",
      "           tp  \n",
      "276  0.000013  \n",
      "277  0.000011  \n",
      "278  0.000009  \n",
      "279  0.000008  \n",
      "280  0.000014  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8760 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2021_london_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time        tp\n",
      "time                                                                     \n",
      "2020-12-31 1 days 00:00:00       0      0.0 2021-01-01 00:00:00  0.000013\n",
      "2021-01-01 0 days 01:00:00       0      0.0 2021-01-01 01:00:00  0.000001\n",
      "2021-01-01 0 days 02:00:00       0      0.0 2021-01-01 02:00:00  0.000002\n",
      "2021-01-01 0 days 03:00:00       0      0.0 2021-01-01 03:00:00  0.000003\n",
      "2021-01-01 0 days 04:00:00       0      0.0 2021-01-01 04:00:00  0.000004\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 288 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2021_london_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.02 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude     longitude  number  surface        tp\n",
      "0 0 days 01:00:00      51.6 -2.000000e-01       0      0.0  0.000085\n",
      "1 0 days 01:00:00      51.6 -1.000000e-01       0      0.0  0.000087\n",
      "2 0 days 01:00:00      51.6  2.775558e-17       0      0.0  0.000090\n",
      "3 0 days 01:00:00      51.6  1.000000e-01       0      0.0  0.000094\n",
      "4 0 days 01:00:00      51.5 -2.000000e-01       0      0.0  0.000085\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2021_london_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2021_london_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2021_london_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 105120 rows\n"
     ]
    }
   ],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2021\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2021 = process_my_data(ds, \"2021_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c15daad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>step</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>number</th>\n",
       "      <th>surface</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>51.6</td>\n",
       "      <td>-2.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>51.6</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>51.6</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>51.6</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>51.5</td>\n",
       "      <td>-2.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time             step  latitude     longitude  number  surface  \\\n",
       "0  2020-12-31  1 days 00:00:00      51.6 -2.000000e-01       0      0.0   \n",
       "1  2020-12-31  1 days 00:00:00      51.6 -1.000000e-01       0      0.0   \n",
       "2  2020-12-31  1 days 00:00:00      51.6  2.775558e-17       0      0.0   \n",
       "3  2020-12-31  1 days 00:00:00      51.6  1.000000e-01       0      0.0   \n",
       "4  2020-12-31  1 days 00:00:00      51.5 -2.000000e-01       0      0.0   \n",
       "\n",
       "            valid_time        tp  \n",
       "0  2021-01-01 00:00:00  0.000013  \n",
       "1  2021-01-01 00:00:00  0.000011  \n",
       "2  2021-01-01 00:00:00  0.000009  \n",
       "3  2021-01-01 00:00:00  0.000008  \n",
       "4  2021-01-01 00:00:00  0.000014  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e85b4d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>step</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>number</th>\n",
       "      <th>surface</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105115</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.5</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-31 23:00:00</td>\n",
       "      <td>0.001947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105116</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>-2.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-31 23:00:00</td>\n",
       "      <td>0.001738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105117</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-31 23:00:00</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105118</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-31 23:00:00</td>\n",
       "      <td>0.001658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105119</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-12-31 23:00:00</td>\n",
       "      <td>0.001421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              time             step  latitude     longitude  number  surface  \\\n",
       "105115  2021-12-31  0 days 23:00:00      51.5  1.000000e-01       0      0.0   \n",
       "105116  2021-12-31  0 days 23:00:00      51.4 -2.000000e-01       0      0.0   \n",
       "105117  2021-12-31  0 days 23:00:00      51.4 -1.000000e-01       0      0.0   \n",
       "105118  2021-12-31  0 days 23:00:00      51.4  2.775558e-17       0      0.0   \n",
       "105119  2021-12-31  0 days 23:00:00      51.4  1.000000e-01       0      0.0   \n",
       "\n",
       "                 valid_time        tp  \n",
       "105115  2021-12-31 23:00:00  0.001947  \n",
       "105116  2021-12-31 23:00:00  0.001738  \n",
       "105117  2021-12-31 23:00:00  0.001678  \n",
       "105118  2021-12-31 23:00:00  0.001658  \n",
       "105119  2021-12-31 23:00:00  0.001421  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2021.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfef4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3b96e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: london_era5land_hourly_tp_2022.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: .\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2021-12-31T00:00:00.000000000 to 2022-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 51.4 to 51.6 (3 points)\n",
      "   longitude: -0.2 to 0.1 (4 points)\n",
      "   valid_time: 2021-12-31T01:00:00.000000000 to 2023-01-01T00:00:00.000000000 (8784 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2021-12-31T00:00:00.000000000 to 2022-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: [51.6 51.5 51.4]\n",
      "   longitude: [-2.00000000e-01 -1.00000000e-01  2.77555756e-17  1.00000000e-01]\n",
      "   valid_time: ['2021-12-31T01:00:00.000000000' '2021-12-31T02:00:00.000000000'\n",
      " '2021-12-31T03:00:00.000000000' '2021-12-31T04:00:00.000000000'\n",
      " '2021-12-31T05:00:00.000000000' '2021-12-31T06:00:00.000000000'\n",
      " '2021-12-31T07:00:00.000000000' '2021-12-31T08:00:00.000000000'\n",
      " '2021-12-31T09:00:00.000000000' '2021-12-31T10:00:00.000000000'\n",
      " '2021-12-31T11:00:00.000000000' '2021-12-31T12:00:00.000000000'\n",
      " '2021-12-31T13:00:00.000000000' '2021-12-31T14:00:00.000000000'\n",
      " '2021-12-31T15:00:00.000000000' '2021-12-31T16:00:00.000000000'\n",
      " '2021-12-31T17:00:00.000000000' '2021-12-31T18:00:00.000000000'\n",
      " '2021-12-31T19:00:00.000000000' '2021-12-31T20:00:00.000000000'\n",
      " '2021-12-31T21:00:00.000000000' '2021-12-31T22:00:00.000000000'\n",
      " '2021-12-31T23:00:00.000000000' '2022-01-01T00:00:00.000000000'] to ['2022-12-31T01:00:00.000000000' '2022-12-31T02:00:00.000000000'\n",
      " '2022-12-31T03:00:00.000000000' '2022-12-31T04:00:00.000000000'\n",
      " '2022-12-31T05:00:00.000000000' '2022-12-31T06:00:00.000000000'\n",
      " '2022-12-31T07:00:00.000000000' '2022-12-31T08:00:00.000000000'\n",
      " '2022-12-31T09:00:00.000000000' '2022-12-31T10:00:00.000000000'\n",
      " '2022-12-31T11:00:00.000000000' '2022-12-31T12:00:00.000000000'\n",
      " '2022-12-31T13:00:00.000000000' '2022-12-31T14:00:00.000000000'\n",
      " '2022-12-31T15:00:00.000000000' '2022-12-31T16:00:00.000000000'\n",
      " '2022-12-31T17:00:00.000000000' '2022-12-31T18:00:00.000000000'\n",
      " '2022-12-31T19:00:00.000000000' '2022-12-31T20:00:00.000000000'\n",
      " '2022-12-31T21:00:00.000000000' '2022-12-31T22:00:00.000000000'\n",
      " '2022-12-31T23:00:00.000000000' '2023-01-01T00:00:00.000000000'] (8784 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (366, 24, 3, 4)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.0299998726695776\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 105120 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2022_london_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 8.38 MB\n",
      "📊 Long format sample:\n",
      "          time   step  latitude     longitude  number  surface valid_time  \\\n",
      "276 2021-12-31 1 days      51.6 -2.000000e-01       0      0.0 2022-01-01   \n",
      "277 2021-12-31 1 days      51.6 -1.000000e-01       0      0.0 2022-01-01   \n",
      "278 2021-12-31 1 days      51.6  2.775558e-17       0      0.0 2022-01-01   \n",
      "279 2021-12-31 1 days      51.6  1.000000e-01       0      0.0 2022-01-01   \n",
      "280 2021-12-31 1 days      51.5 -2.000000e-01       0      0.0 2022-01-01   \n",
      "\n",
      "           tp  \n",
      "276  0.002712  \n",
      "277  0.002751  \n",
      "278  0.002790  \n",
      "279  0.002478  \n",
      "280  0.002195  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8760 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2022_london_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time            tp\n",
      "time                                                                         \n",
      "2021-12-31 1 days 00:00:00       0      0.0 2022-01-01 00:00:00  2.154291e-03\n",
      "2022-01-01 0 days 01:00:00       0      0.0 2022-01-01 01:00:00  1.889033e-07\n",
      "2022-01-01 0 days 02:00:00       0      0.0 2022-01-01 02:00:00  1.890585e-07\n",
      "2022-01-01 0 days 03:00:00       0      0.0 2022-01-01 03:00:00  1.890585e-07\n",
      "2022-01-01 0 days 04:00:00       0      0.0 2022-01-01 04:00:00  1.890585e-07\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 288 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2022_london_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.02 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude     longitude  number  surface        tp\n",
      "0 0 days 01:00:00      51.6 -2.000000e-01       0      0.0  0.000057\n",
      "1 0 days 01:00:00      51.6 -1.000000e-01       0      0.0  0.000055\n",
      "2 0 days 01:00:00      51.6  2.775558e-17       0      0.0  0.000054\n",
      "3 0 days 01:00:00      51.6  1.000000e-01       0      0.0  0.000055\n",
      "4 0 days 01:00:00      51.5 -2.000000e-01       0      0.0  0.000055\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2022_london_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2022_london_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2022_london_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 105120 rows\n"
     ]
    }
   ],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2022\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2022 = process_my_data(ds, \"2022_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10be15d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105120, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2022.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "601622e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>step</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>number</th>\n",
       "      <th>surface</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105115</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.5</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>0.008670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105116</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>-2.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>0.009620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105117</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>0.010117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105118</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>0.010687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105119</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0 days 23:00:00</td>\n",
       "      <td>51.4</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12-31 23:00:00</td>\n",
       "      <td>0.010271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              time             step  latitude     longitude  number  surface  \\\n",
       "105115  2022-12-31  0 days 23:00:00      51.5  1.000000e-01       0      0.0   \n",
       "105116  2022-12-31  0 days 23:00:00      51.4 -2.000000e-01       0      0.0   \n",
       "105117  2022-12-31  0 days 23:00:00      51.4 -1.000000e-01       0      0.0   \n",
       "105118  2022-12-31  0 days 23:00:00      51.4  2.775558e-17       0      0.0   \n",
       "105119  2022-12-31  0 days 23:00:00      51.4  1.000000e-01       0      0.0   \n",
       "\n",
       "                 valid_time        tp  \n",
       "105115  2022-12-31 23:00:00  0.008670  \n",
       "105116  2022-12-31 23:00:00  0.009620  \n",
       "105117  2022-12-31 23:00:00  0.010117  \n",
       "105118  2022-12-31 23:00:00  0.010687  \n",
       "105119  2022-12-31 23:00:00  0.010271  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2022.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2025\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2025 = process_my_data(ds, \"2025_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122e5277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>number</th>\n",
       "      <th>surface</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-01-01 00:00:00</td>\n",
       "      <td>1.214221e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 days 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-01-01 01:00:00</td>\n",
       "      <td>9.459133e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 days 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-01-01 02:00:00</td>\n",
       "      <td>1.864197e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 days 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-01-01 03:00:00</td>\n",
       "      <td>1.998929e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 days 04:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-01-01 04:00:00</td>\n",
       "      <td>2.486942e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              step  number  surface           valid_time            tp\n",
       "0  1 days 00:00:00       0      0.0  2025-01-01 00:00:00  1.214221e-04\n",
       "1  0 days 01:00:00       0      0.0  2025-01-01 01:00:00  9.459133e-07\n",
       "2  0 days 02:00:00       0      0.0  2025-01-01 02:00:00  1.864197e-06\n",
       "3  0 days 03:00:00       0      0.0  2025-01-01 03:00:00  1.998929e-06\n",
       "4  0 days 04:00:00       0      0.0  2025-01-01 04:00:00  2.486942e-06"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2025 = pd.read_csv('./data/2025_london_era5_precipitation_time_series.csv', comment='#')\n",
    "df_2025.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcccd102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step           object\n",
       "number          int64\n",
       "surface       float64\n",
       "valid_time     object\n",
       "tp            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2025.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a80599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: london_era5land_hourly_tp_2024.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: .\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 367, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2023-12-31T00:00:00.000000000 to 2024-12-31T00:00:00.000000000 (367 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 51.4 to 51.6 (3 points)\n",
      "   longitude: -0.2 to 0.1 (4 points)\n",
      "   valid_time: 2023-12-31T01:00:00.000000000 to 2025-01-01T00:00:00.000000000 (8808 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 367, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2023-12-31T00:00:00.000000000 to 2024-12-31T00:00:00.000000000 (367 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: [51.6 51.5 51.4]\n",
      "   longitude: [-2.00000000e-01 -1.00000000e-01  2.77555756e-17  1.00000000e-01]\n",
      "   valid_time: ['2023-12-31T01:00:00.000000000' '2023-12-31T02:00:00.000000000'\n",
      " '2023-12-31T03:00:00.000000000' '2023-12-31T04:00:00.000000000'\n",
      " '2023-12-31T05:00:00.000000000' '2023-12-31T06:00:00.000000000'\n",
      " '2023-12-31T07:00:00.000000000' '2023-12-31T08:00:00.000000000'\n",
      " '2023-12-31T09:00:00.000000000' '2023-12-31T10:00:00.000000000'\n",
      " '2023-12-31T11:00:00.000000000' '2023-12-31T12:00:00.000000000'\n",
      " '2023-12-31T13:00:00.000000000' '2023-12-31T14:00:00.000000000'\n",
      " '2023-12-31T15:00:00.000000000' '2023-12-31T16:00:00.000000000'\n",
      " '2023-12-31T17:00:00.000000000' '2023-12-31T18:00:00.000000000'\n",
      " '2023-12-31T19:00:00.000000000' '2023-12-31T20:00:00.000000000'\n",
      " '2023-12-31T21:00:00.000000000' '2023-12-31T22:00:00.000000000'\n",
      " '2023-12-31T23:00:00.000000000' '2024-01-01T00:00:00.000000000'] to ['2024-12-31T01:00:00.000000000' '2024-12-31T02:00:00.000000000'\n",
      " '2024-12-31T03:00:00.000000000' '2024-12-31T04:00:00.000000000'\n",
      " '2024-12-31T05:00:00.000000000' '2024-12-31T06:00:00.000000000'\n",
      " '2024-12-31T07:00:00.000000000' '2024-12-31T08:00:00.000000000'\n",
      " '2024-12-31T09:00:00.000000000' '2024-12-31T10:00:00.000000000'\n",
      " '2024-12-31T11:00:00.000000000' '2024-12-31T12:00:00.000000000'\n",
      " '2024-12-31T13:00:00.000000000' '2024-12-31T14:00:00.000000000'\n",
      " '2024-12-31T15:00:00.000000000' '2024-12-31T16:00:00.000000000'\n",
      " '2024-12-31T17:00:00.000000000' '2024-12-31T18:00:00.000000000'\n",
      " '2024-12-31T19:00:00.000000000' '2024-12-31T20:00:00.000000000'\n",
      " '2024-12-31T21:00:00.000000000' '2024-12-31T22:00:00.000000000'\n",
      " '2024-12-31T23:00:00.000000000' '2025-01-01T00:00:00.000000000'] (8808 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (367, 24, 3, 4)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.023042548447847366\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 105408 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2024_london_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 8.45 MB\n",
      "📊 Long format sample:\n",
      "          time   step  latitude     longitude  number  surface valid_time  \\\n",
      "276 2023-12-31 1 days      51.6 -2.000000e-01       0      0.0 2024-01-01   \n",
      "277 2023-12-31 1 days      51.6 -1.000000e-01       0      0.0 2024-01-01   \n",
      "278 2023-12-31 1 days      51.6  2.775558e-17       0      0.0 2024-01-01   \n",
      "279 2023-12-31 1 days      51.6  1.000000e-01       0      0.0 2024-01-01   \n",
      "280 2023-12-31 1 days      51.5 -2.000000e-01       0      0.0 2024-01-01   \n",
      "\n",
      "           tp  \n",
      "276  0.007288  \n",
      "277  0.007406  \n",
      "278  0.007525  \n",
      "279  0.007557  \n",
      "280  0.007369  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8784 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2024_london_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time       tp\n",
      "time                                                                    \n",
      "2023-12-31 1 days 00:00:00       0      0.0 2024-01-01 00:00:00  0.00754\n",
      "2024-01-01 0 days 01:00:00       0      0.0 2024-01-01 01:00:00  0.00000\n",
      "2024-01-01 0 days 02:00:00       0      0.0 2024-01-01 02:00:00  0.00000\n",
      "2024-01-01 0 days 03:00:00       0      0.0 2024-01-01 03:00:00  0.00000\n",
      "2024-01-01 0 days 04:00:00       0      0.0 2024-01-01 04:00:00  0.00000\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 288 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2024_london_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.02 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude     longitude  number  surface        tp\n",
      "0 0 days 01:00:00      51.6 -2.000000e-01       0      0.0  0.000086\n",
      "1 0 days 01:00:00      51.6 -1.000000e-01       0      0.0  0.000081\n",
      "2 0 days 01:00:00      51.6  2.775558e-17       0      0.0  0.000076\n",
      "3 0 days 01:00:00      51.6  1.000000e-01       0      0.0  0.000075\n",
      "4 0 days 01:00:00      51.5 -2.000000e-01       0      0.0  0.000090\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2024_london_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2024_london_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2024_london_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 105408 rows\n"
     ]
    }
   ],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2024\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2024 = process_my_data(ds, \"2024_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f54f9019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️  Processing London Precipitation Data\n",
      "==================================================\n",
      "📦 Extracting ZIP file: london_era5land_hourly_tp_2023.grib\n",
      "📋 Files in archive: ['data.grib']\n",
      "✅ Extracted to: .\n",
      "🎯 Found GRIB file: data.grib\n",
      "📊 Loading GRIB file: data.grib\n",
      "🔄 Trying cfgrib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\cfgrib\\xarray_plugin.py:131: FutureWarning: In a future version, xarray will not decode timedelta values based on the presence of a timedelta-like units attribute by default. Instead it will rely on the presence of a timedelta64 dtype attribute, which is now xarray's default way of encoding timedelta64 values. To continue decoding timedeltas based on the presence of a timedelta-like units attribute, users will need to explicitly opt-in by passing True or CFTimedeltaCoder(decode_via_units=True) to decode_timedelta. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\n",
      "  vars, attrs, coord_names = xr.conventions.decode_cf_variables(\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:131: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dataset dimensions: {dict(ds.dims)}\")\n",
      "c:\\Users\\pacor\\Documents\\Notebooks\\Python\\Data Analysis\\Rainfall\\notebooks\\src\\manage_grib_files.py:260: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"📏 Dimensions: {dict(ds.dims)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Success with cfgrib!\n",
      "📏 Dataset dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "\n",
      "📈 Data Summary:\n",
      "==============================\n",
      "🗺️  Coordinates:\n",
      "   number: 0\n",
      "   time: 2022-12-31T00:00:00.000000000 to 2023-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: 51.4 to 51.6 (3 points)\n",
      "   longitude: -0.2 to 0.1 (4 points)\n",
      "   valid_time: 2022-12-31T01:00:00.000000000 to 2024-01-01T00:00:00.000000000 (8784 points)\n",
      "\n",
      "📊 Data Variables:\n",
      "   tp: ('time', 'step', 'latitude', 'longitude') - Total precipitation\n",
      "      Units: m\n",
      "\n",
      "🎉 Success! Dataset loaded successfully.\n",
      "\n",
      "To work with your data:\n",
      "1. Use ds[variable_name] to access variables\n",
      "2. Use ds.sel() or ds.isel() to select data\n",
      "3. Use ds.plot() for quick visualizations\n",
      "🌧️  Processing Your London Precipitation Data\n",
      "==================================================\n",
      "🔍 Dataset Structure Analysis\n",
      "========================================\n",
      "📏 Dimensions: {'time': 366, 'step': 24, 'latitude': 3, 'longitude': 4}\n",
      "📊 Variables: ['tp']\n",
      "🗺️  Coordinates: ['number', 'time', 'step', 'surface', 'latitude', 'longitude', 'valid_time']\n",
      "\n",
      "📍 Coordinate Details:\n",
      "   number: 0\n",
      "   time: 2022-12-31T00:00:00.000000000 to 2023-12-31T00:00:00.000000000 (366 points)\n",
      "   step: 3600000000000 nanoseconds to 86400000000000 nanoseconds (24 points)\n",
      "   surface: 0.0\n",
      "   latitude: [51.6 51.5 51.4]\n",
      "   longitude: [-2.00000000e-01 -1.00000000e-01  2.77555756e-17  1.00000000e-01]\n",
      "   valid_time: ['2022-12-31T01:00:00.000000000' '2022-12-31T02:00:00.000000000'\n",
      " '2022-12-31T03:00:00.000000000' '2022-12-31T04:00:00.000000000'\n",
      " '2022-12-31T05:00:00.000000000' '2022-12-31T06:00:00.000000000'\n",
      " '2022-12-31T07:00:00.000000000' '2022-12-31T08:00:00.000000000'\n",
      " '2022-12-31T09:00:00.000000000' '2022-12-31T10:00:00.000000000'\n",
      " '2022-12-31T11:00:00.000000000' '2022-12-31T12:00:00.000000000'\n",
      " '2022-12-31T13:00:00.000000000' '2022-12-31T14:00:00.000000000'\n",
      " '2022-12-31T15:00:00.000000000' '2022-12-31T16:00:00.000000000'\n",
      " '2022-12-31T17:00:00.000000000' '2022-12-31T18:00:00.000000000'\n",
      " '2022-12-31T19:00:00.000000000' '2022-12-31T20:00:00.000000000'\n",
      " '2022-12-31T21:00:00.000000000' '2022-12-31T22:00:00.000000000'\n",
      " '2022-12-31T23:00:00.000000000' '2023-01-01T00:00:00.000000000'] to ['2023-12-31T01:00:00.000000000' '2023-12-31T02:00:00.000000000'\n",
      " '2023-12-31T03:00:00.000000000' '2023-12-31T04:00:00.000000000'\n",
      " '2023-12-31T05:00:00.000000000' '2023-12-31T06:00:00.000000000'\n",
      " '2023-12-31T07:00:00.000000000' '2023-12-31T08:00:00.000000000'\n",
      " '2023-12-31T09:00:00.000000000' '2023-12-31T10:00:00.000000000'\n",
      " '2023-12-31T11:00:00.000000000' '2023-12-31T12:00:00.000000000'\n",
      " '2023-12-31T13:00:00.000000000' '2023-12-31T14:00:00.000000000'\n",
      " '2023-12-31T15:00:00.000000000' '2023-12-31T16:00:00.000000000'\n",
      " '2023-12-31T17:00:00.000000000' '2023-12-31T18:00:00.000000000'\n",
      " '2023-12-31T19:00:00.000000000' '2023-12-31T20:00:00.000000000'\n",
      " '2023-12-31T21:00:00.000000000' '2023-12-31T22:00:00.000000000'\n",
      " '2023-12-31T23:00:00.000000000' '2024-01-01T00:00:00.000000000'] (8784 points)\n",
      "\n",
      "📊 Variable Details:\n",
      "   tp:\n",
      "      Shape: (366, 24, 3, 4)\n",
      "      Dimensions: ('time', 'step', 'latitude', 'longitude')\n",
      "      Units: m\n",
      "      Description: Total precipitation\n",
      "      Data range: 0.0 to 0.019860848784446716\n",
      "\n",
      "==================================================\n",
      "🚀 Creating multiple CSV formats...\n",
      "========================================\n",
      "📊 Converting to Long Format DataFrame...\n",
      "✅ Created DataFrame with 105120 rows and 8 columns\n",
      "📊 Columns: ['time', 'step', 'latitude', 'longitude', 'number', 'surface', 'valid_time', 'tp']\n",
      "💾 Saving DataFrame to: 2023_london_era5_precipitation_long_format.csv\n",
      "✅ Saved successfully! File size: 8.41 MB\n",
      "📊 Long format sample:\n",
      "          time   step  latitude     longitude  number  surface valid_time  \\\n",
      "276 2022-12-31 1 days      51.6 -2.000000e-01       0      0.0 2023-01-01   \n",
      "277 2022-12-31 1 days      51.6 -1.000000e-01       0      0.0 2023-01-01   \n",
      "278 2022-12-31 1 days      51.6  2.775558e-17       0      0.0 2023-01-01   \n",
      "279 2022-12-31 1 days      51.6  1.000000e-01       0      0.0 2023-01-01   \n",
      "280 2022-12-31 1 days      51.5 -2.000000e-01       0      0.0 2023-01-01   \n",
      "\n",
      "           tp  \n",
      "276  0.006293  \n",
      "277  0.006996  \n",
      "278  0.007697  \n",
      "279  0.007415  \n",
      "280  0.007895  \n",
      "\n",
      "📈 Converting to Time Series DataFrame (spatial aggregation: mean)...\n",
      "   Aggregated 2 spatial dimensions using mean\n",
      "✅ Created time series DataFrame with 8760 rows and 5 columns\n",
      "💾 Saving DataFrame to: 2023_london_era5_precipitation_time_series.csv\n",
      "✅ Saved successfully! File size: 0.46 MB\n",
      "📈 Time series sample:\n",
      "                      step  number  surface          valid_time        tp\n",
      "time                                                                     \n",
      "2022-12-31 1 days 00:00:00       0      0.0 2023-01-01 00:00:00  0.008758\n",
      "2023-01-01 0 days 01:00:00       0      0.0 2023-01-01 01:00:00  0.000136\n",
      "2023-01-01 0 days 02:00:00       0      0.0 2023-01-01 02:00:00  0.000141\n",
      "2023-01-01 0 days 03:00:00       0      0.0 2023-01-01 03:00:00  0.000141\n",
      "2023-01-01 0 days 04:00:00       0      0.0 2023-01-01 04:00:00  0.000148\n",
      "\n",
      "🗺️  Converting to Spatial DataFrame (time aggregation: mean)...\n",
      "   Aggregated time dimension using mean\n",
      "✅ Created spatial DataFrame with 288 rows and 6 columns\n",
      "💾 Saving DataFrame to: 2023_london_era5_precipitation_spatial_average.csv\n",
      "✅ Saved successfully! File size: 0.02 MB\n",
      "🗺️  Spatial average sample:\n",
      "             step  latitude     longitude  number  surface        tp\n",
      "0 0 days 01:00:00      51.6 -2.000000e-01       0      0.0  0.000099\n",
      "1 0 days 01:00:00      51.6 -1.000000e-01       0      0.0  0.000101\n",
      "2 0 days 01:00:00      51.6  2.775558e-17       0      0.0  0.000103\n",
      "3 0 days 01:00:00      51.6  1.000000e-01       0      0.0  0.000104\n",
      "4 0 days 01:00:00      51.5 -2.000000e-01       0      0.0  0.000097\n",
      "\n",
      "\n",
      "🎉 Processing complete! Created 3 files:\n",
      "   📄 long_format: 2023_london_era5_precipitation_long_format.csv\n",
      "   📄 time_series: 2023_london_era5_precipitation_time_series.csv\n",
      "   📄 spatial_average: 2023_london_era5_precipitation_spatial_average.csv\n",
      "\n",
      "💡 Returning long format DataFrame with 105120 rows\n"
     ]
    }
   ],
   "source": [
    "out_file = \"london_era5land_hourly_tp_2023\"\n",
    "grib_file = out_file + '.grib'\n",
    "\n",
    "ds = process_london_precipitation_data(grib_file)\n",
    "    \n",
    "if ds is not None:\n",
    "    print(\"\\n🎉 Success! Dataset loaded successfully.\")\n",
    "    print(\"\\nTo work with your data:\")\n",
    "    print(\"1. Use ds[variable_name] to access variables\")\n",
    "    print(\"2. Use ds.sel() or ds.isel() to select data\")\n",
    "    print(\"3. Use ds.plot() for quick visualizations\")\n",
    "\n",
    "df_2024 = process_my_data(ds, \"2023_london_era5_precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5748f831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105120, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2024.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ceb79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84eaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
